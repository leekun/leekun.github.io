<!DOCTYPE HTML>

    <html lang="zh-Hans">
  
<head>
  <meta charset="utf-8">
  
  <title>归档：2016/11 | CastellanZhang&#39;s blog</title>
  <meta name="author" content="CastellanZhang">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
  <meta property="og:site_name" content="CastellanZhang&#39;s blog"/>

  
    <meta property="og:image" content="undefined"/>
  

  
    <meta http-equiv="Content-Language" content="zh-Hans"/>
  

  <link href="/img/favicon.png" rel="icon">
  
    <link rel="apple-touch-icon" href="/img/apple-icon.png">
    <link rel="apple-touch-icon-precomposed" href="/img/apple-icon.png">
    

  <link rel="alternate" href="/atom.xml" title="CastellanZhang&#39;s blog" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  
  <style type="text/css">
  /* Tim Pietrusky advanced checkbox hack (Android <= 4.1.2) */
body{ -webkit-animation: bugfix infinite 1s; }
@-webkit-keyframes bugfix { from {padding:0;} to {padding:0;} }

  
  <!-- Chinese readability improvements -->
    article {font-weight: 400;letter-spacing: .01rem;}
    article .entry{line-height:2;}
  

  
    article .post-content-index .entry{max-height: 550px; overflow:hidden;}
  
</style>

  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->

  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'null', 'auto');
  ga('send', 'pageview');
 
</script>




  
    <!-- 360 Font and Baidu CDN in China -->
    
      <link href='http://fonts.useso.com/css?family=Open+Sans:300,400|Playball' rel='stylesheet' type='text/css'>
    
  <link href='http://apps.bdimg.com/libs/fontawesome/4.1.0/css/font-awesome.css' rel='stylesheet' type='text/css'>
  <script src="http://libs.baidu.com/jquery/1.11.1/jquery.min.js"></script>
  



</head>


<body>
  <header id="header" class="inner"><div class="padding">
	<div class="alignleft logo">
	  <h1><a href="/">CastellanZhang&#39;s blog</a></h1>
	</div>
	<nav id="main-nav" class="alignright">
		<input type="checkbox" id="toggle" />
		<label for="toggle" class="toggle" data-open="Main Menu" data-close="Close Menu" onclick><i class="fa fa-bars"></i></label>
	  <ul class="menu">
	    
	      <li><a href="/">Home</a></li>
	    
	      <li><a href="/archives">Archives</a></li>
	    
	    
	  </ul>
	</nav>
	<div class="clearfix"></div>
</div>
</header>
  <div id="page-heading-wrap">
  	<div class="inner">
      <div class="padding">
    		
          <h2></h2>
        
      </div>
  	</div>
  </div>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper" class="padding">
<h2 class="archive-title">2016/11</h2>


  
    <article class="post">
  
  
    <div class="post-content-index">
  
      
        <header>
          <div class="icon"></div>
            
    
      <h1 class="title transition"><a href="/2016/11/22/ensembling_lagrange/">Ensembling, Lagrange</a></h1>
    
  
          <ul>
            <li>
              <span class="heading-span">Posted on: </span>
              <time datetime="2016-11-22T07:31:26.000Z">Nov 22 2016</time>
            </li>
            
              <li>
                <span class="heading-span">By: </span>

                
                  <a href="/">CastellanZhang</a>
                

              </li>
            
            <li>
              <span class="heading-span">With: </span>
              
          </ul>
        </header>
      
      <div class="entry">
        
          
            <h1 id="Ensembling_2C_Lagrange"><a href="#Ensembling_2C_Lagrange" class="headerlink" title="Ensembling, Lagrange"></a>Ensembling, Lagrange</h1><p>　　据我观察，名字带“拉”的人一般都很厉害，比如马拉多纳、希拉里、狄波拉、张娜拉、杜拉拉、陈法拉、尼古拉斯·赵四、地铁站的罗拉……</p>
<p>　　但跟我们今天的大神拉格朗日（Lagrange）一比就都被秒成了渣渣，因为每一个上过高数和物理的我们都被拉大神无情碾压摩擦过啊~</p>
<p>　　童鞋，请站起来回答拉格朗日中值定律是啥？</p>
<p>　　童鞋，请站起来回答拉格朗日乘子法是啥？</p>
<p>　　童鞋，请站起来回答拉格朗日内插公式是啥？</p>
<p>　　童鞋，请站起来回答拉格朗日点是啥？</p>
<p>　　童鞋，请站起来回答拉格朗日函数是啥？</p>
<p>　　童鞋，请站起来回答拉格朗日方程是啥？</p>
<p>　　……</p>
<p>　　童鞋，你肿么站不起来了童鞋？<br><br><br>　　请原谅我召唤出封印在你们心底多年的梦魇，快跟我一起踏碎时空大逃亡，继续闪回到小米数据挖掘大赛那几天。</p>
<p>　　<a href="http://castellanzhang.github.io/2016/10/16/fm_ftrl_softmax/" target="_blank" rel="external">上文</a>中已经提到我们最终的模型不止一个，而是多个DNN和FM共七八个模型的融合。</p>
<p>　　所谓模型融合，洋气一点叫Ensembling，在 <a href="http://mlwave.com/kaggle-ensembling-guide/" target="_blank" rel="external">http://mlwave.com/kaggle-ensembling-guide/</a> 一文中有详细介绍。简单来说就是综合多个单模型的输出来给出最终的结果，一般会比每个单模型的效果都好，现在已经是各大比赛的常规武器。但对于初涉江湖的小伙伴们还没有太多经验，一开始只是简单的平均，后来尝试了各个模型的输出做为LR的特征，发现没啥卵用，比赛已近尾声就没再折腾更复杂的方法，最终使用线性加权平均，即：<br>$$<br>\hat y=w_1\hat y_1+w_2\hat y_2+…+w_M\hat y_M<br>$$<br>　　其中，$w_1+w_2+…+w_M=1$</p>
<p>　　这里有个问题就是权重系数怎么定？</p>
<p>　　一开始就是拍脑袋定，单模型效果好的权重就大一点，效果差的就小一点。后来小伙伴使用暴力网格搜索的方法，融合两三个模型还行，再多就已经慢到不可接受。</p>
<p>　　我看在眼里急在心头，我们是模武双修的种族啊，怎么能只用暴力解决呢？这种目标如此鲜明灿若煌煌皓月的好问题，当然要祭出流光华丽的大模型才相得益彰呢！</p>
<h2 id="u7B2C_u4E00_u5F0F_uFF1A_u6DF7_u6C8C_u521D_u5206_u6A21_u578B_u73B0_uFF01"><a href="#u7B2C_u4E00_u5F0F_uFF1A_u6DF7_u6C8C_u521D_u5206_u6A21_u578B_u73B0_uFF01" class="headerlink" title="第一式：混沌初分模型现！"></a>第一式：混沌初分模型现！</h2><p>　　比如我们有M个单模型分类器，解决K分类问题，测试集包含N条样本，$\hat{y}_{nmk}$ 表示第m个单模型对第n条样本属于第k类的预测概率。</p>
<p>　　我们采用线性加权平均的方法，融合M个模型得到的预测概率<br>$$<br>\hat{y}_{nk}=\sum_{m=1}^{M-1}w_m\hat{y}_{nmk}+(1-\sum_{m=1}^{M-1}w_m)\hat{y}_{nMk}<br>$$<br>　　比赛评价标准为logloss，我们希望融合后的模型在测试集上的logloss尽量小，所以优化目标如下：<br>$$<br>\min_{w}f(w)=\min_{w}\{-\frac{1}{N}\sum_{n=1}^{N}\sum_{k=1}^{K}1\{y_n=k\}\ln\hat{y}_{nk}\}\\<br>=\min_{w}\{-\frac{1}{N}\sum_{n=1}^N\sum_{k=1}^{K}1\{y_n=k\}\ln(\sum_{m=1}^{M-1}w_m\hat{y}_{nmk}+(1-\sum_{m=1}^{M-1}w_m)\hat{y}_{nMk})\}<br>$$<br>　　其中$w=[w_1,..,w_{M-1}]^T$是需要求解的权重参数，我们知道权重之和要归一，所以不需要$w_M$这一变量，用$1-\sum_{m=1}^{M-1}w_m$代替即可。</p>
<p>　　问题已明确，下面来求解。</p>
<h2 id="u7B2C_u4E8C_u5F0F_uFF1A_u68AF_u5EA6_u6740_uFF01_uFF01"><a href="#u7B2C_u4E8C_u5F0F_uFF1A_u68AF_u5EA6_u6740_uFF01_uFF01" class="headerlink" title="第二式：梯度杀！！"></a>第二式：梯度杀！！</h2><p>　　这一招早已驾轻就熟，直接求梯度，然后上sgd或adagrad。单条样本的损失函数为<br>$$<br>l_n(w)=-\sum_{k=1}^{K}1\{y_n=k\}\ln(\sum_{m=1}^{M-1}w_m\hat{y}_{nmk}+(1-\sum_{m=1}^{M-1}w_m)\hat{y}_{nMk})<br>$$<br>　　梯度为<br>$$<br>\frac{\partial l_n}{\partial w_m}=-\sum_{k=1}^{K}1\{y_n=k\}\frac{\hat{y}_{nmk}-\hat{y}_{nMk}}{\hat{y}_{nk}},\quad m=1,…,M-1<br>$$<br>　　adagrad版本的代码如下，注意其中变量名和上面的公式并不完全一致，类别编号是从0到K-1（我就是这么洒脱随性~）<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys, math</span><br><span class="line"></span><br><span class="line">classNum = int(sys.argv[<span class="number">1</span>])</span><br><span class="line">modelNum = int(sys.argv[<span class="number">2</span>])</span><br><span class="line">alfa = float(sys.argv[<span class="number">3</span>])</span><br><span class="line">beta = <span class="number">1.0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> &gt;&gt; sys.stderr, <span class="string">"classNum="</span> + str(classNum)</span><br><span class="line"><span class="keyword">print</span> &gt;&gt; sys.stderr, <span class="string">"modelNum="</span> + str(modelNum)</span><br><span class="line"><span class="keyword">print</span> &gt;&gt; sys.stderr, <span class="string">"alfa="</span> + str(alfa)</span><br><span class="line"></span><br><span class="line">w = [<span class="number">1.0</span>] * modelNum</span><br><span class="line">n = [<span class="number">0.0</span>] * (modelNum-<span class="number">1</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(w)):</span><br><span class="line">    w[i] /= modelNum</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> &gt;&gt; sys.stderr, w</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    seg = line.rstrip().split(<span class="string">" "</span>)</span><br><span class="line">    label = int(seg[<span class="number">0</span>])</span><br><span class="line">    x = []</span><br><span class="line">    <span class="keyword">for</span> tmp <span class="keyword">in</span> seg[<span class="number">1</span>:]:</span><br><span class="line">        seg2 = tmp.split(<span class="string">","</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(seg2)):</span><br><span class="line">            seg2[i] = float(seg2[i])</span><br><span class="line">        x.append(seg2)</span><br><span class="line">    pre = [<span class="number">0.0</span>] * classNum</span><br><span class="line">    <span class="keyword">for</span> m <span class="keyword">in</span> range(modelNum):</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> range(classNum):</span><br><span class="line">            pre[k] += w[m]*x[m][k]</span><br><span class="line">    g = [<span class="number">0.0</span>] * (modelNum-<span class="number">1</span>)</span><br><span class="line">    wsum = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> m <span class="keyword">in</span> range(modelNum-<span class="number">1</span>):</span><br><span class="line">        g[m] = (x[modelNum-<span class="number">1</span>][label]-x[m][label])/pre[label]</span><br><span class="line">        n[m] += g[m] * g[m]</span><br><span class="line">        lr = alfa/(beta+math.sqrt(n[m]))</span><br><span class="line">        w[m] -= lr * g[m]</span><br><span class="line">        wsum += w[m]</span><br><span class="line">    w[modelNum-<span class="number">1</span>] = <span class="number">1</span>-wsum</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> w:</span><br><span class="line">    <span class="keyword">print</span> x</span><br></pre></td></tr></table></figure></p>
<p>　　输入数据的格式如下：</p>
<p><code>label score11,score12,...,score1K score21,score22,...,score2K ... scoreM1,scoreM2,...,scoreMK</code></p>
<p>　　举个例子，比如二分类4个模型的数据片段如下：</p>
<pre><code>0 0.912427,0.0875725 0.905673,0.0943273 0.911398,0.088602 0.933166,0.066834
0 0.86061,0.139389 0.865925,0.134075 0.881552,0.118448 0.872196,0.127804
1 0.364299,0.635701 0.32974,0.67026 0.323839,0.676161 0.341047,0.658953
0 0.715563,0.284437 0.713995,0.286005 0.713599,0.286401 0.713383,0.286617
0 0.948186,0.0518137 0.925587,0.0744127 0.929451,0.0705489 0.939952,0.0600485
0 0.58531,0.41469 0.588321,0.411679 0.520456,0.479544 0.671846,0.328154
1 0.0154455,0.984554 0.0150741,0.984926 0.0118866,0.988113 0.0109413,0.989059
1 0.0472074,0.952793 0.0612501,0.93875 0.065446,0.934554 0.061947,0.938053
1 0.430228,0.569772 0.366636,0.633364 0.337206,0.662794 0.5487,0.4513
0 0.97958,0.0204195 0.980348,0.0196517 0.979461,0.0205394 0.985608,0.0143915
</code></pre><p>　　我们的测试数据共200多万条，时间复杂度跟单模型数M呈线性关系，跑一次也就分分钟的事。为了验证算法，做了对比，对于3模型融合跑出的结果和暴力求解的结果一致。</p>
<p>　　问题似乎就这么完美解决了，但人生就像直流充电桩，上一秒还是70A的电流，下一秒就可能跳电。当我们融合更多模型时问题出现了，有的权重算出了负值！就像下面这样：</p>
<pre><code>0.120181463777    gender_cut_ftrl8000_val
0.0929962960391   gender_cut_ftrl_val
0.0245135332374   gender_nn_1005_val
0.269705618425    gender_cut_ftrl2000_val
0.422565675064    gender_cut_ftrl1000_val
0.233316720486    gender_newFM_val
0.0228310140994   gender_xxFM_val
-0.186110321128   gender_result_fm
</code></pre><p>导致最终模型的预测概率有可能大于1或小于0，这如何能忍，必须再创新招！</p>
<h2 id="u7B2C_u4E09_u5F0F_uFF1A_u751F_u6B7B_u7B26_uFF01_uFF01_uFF01"><a href="#u7B2C_u4E09_u5F0F_uFF1A_u751F_u6B7B_u7B26_uFF01_uFF01_uFF01" class="headerlink" title="第三式：生死符！！！"></a>第三式：生死符！！！</h2><p>　　“这生死符一发作，一日厉害一日，奇痒剧痛递加九九八十一日，然后逐步减退，八十一日之后，又再递增，如此周而复始，永无休止。每年我派人巡行各洞各岛，赐以镇痛止痒之药，这生死符一年之内便可不发。”</p>
<p>　　好啦，不吓你啦，这是金庸老先生笔下天山童姥的生死符。我这里的生死符简单得很，顾名思义，由权重符号决定单模型生死，正的留，负的弃，留下的单模型重新计算权重，有可能又有新的负值出现，再次使用生死符，直到剩下的单模型权重全部大于等于0。</p>
<p>　　还以上面那次融合为例，最终把gender_xxFM_val和gender_result_fm都干掉了，剩下的权重为：</p>
<pre><code>0.122788741689    gender_cut_ftrl8000_val
0.0782434412719   gender_cut_ftrl_val
0.0331138038226   gender_nn_1005_val
0.24358375583     gender_cut_ftrl2000_val
0.446465338463    gender_cut_ftrl1000_val
0.0758049189234   gender_newFM_val
</code></pre><p>　　在测试集上的logloss = 0.435116，而其中单模型最好的logloss是0.436593。</p>
<p>　　相应地，这批融合在7分类问题age上效果更加明显，从最好的单模型1.35416降到1.35061。<br><br><br>　　以上便是比赛期间我们使用的全部招式。</p>
<p><br><br><br><br><br><br><br>　　憋走，故事还没结束，忘了塞纳河畔的拉格朗日了吗？</p>
<p>　　像我这等追求卓越的好青年岂能够留下不完美的话柄，虽然比赛结束了，我还是要把它彻底解决掉——快使出</p>
<h2 id="u7B2C_u56DB_u5F0F_uFF1A_u94C1_u9501_u6A2A_u6C5F_uFF01_uFF01_uFF01_uFF01"><a href="#u7B2C_u56DB_u5F0F_uFF1A_u94C1_u9501_u6A2A_u6C5F_uFF01_uFF01_uFF01_uFF01" class="headerlink" title="第四式：铁锁横江！！！！"></a>第四式：铁锁横江！！！！</h2><p>　　分析上面的模型，出现负值，是因为少了对w的非负约束，那就加上：<br>$$<br>\min_{w}f(w)=\min_{w}\{-\frac{1}{N}\sum_{n=1}^N\sum_{k=1}^{K}1\{y_n=k\}\ln\hat{y}_{nk}\}\\<br>=\min_{w}\{-\frac{1}{N}\sum_{n=1}^N\sum_{k=1}^{K}1\{y_n=k\}\ln(\sum_{m=1}^{M-1}w_m\hat{y}_{nmk}+(1-\sum_{m=1}^{M-1}w_m)\hat{y}_{nMk})\}<br>$$<br>$$<br>s.t.\quad w_m\ge 0,\quad m=1,2,…,M-1\\<br>1-\sum_{m=1}^{M-1}w_m\ge 0\qquad\qquad<br>$$<br>　　这就成了带约束的优化问题，该怎么解呢？是时候请出拉格朗日大神了！大神蜜汁微笑，抛出一套对偶宝典，将带约束的极小化问题改造成极大极小问题，正是</p>
<h2 id="u7B2C_u4E94_u5F0F_uFF1A_u6CA7_u6D77_u4E00_u7C9F_uFF01_uFF01_uFF01_uFF01_uFF01"><a href="#u7B2C_u4E94_u5F0F_uFF1A_u6CA7_u6D77_u4E00_u7C9F_uFF01_uFF01_uFF01_uFF01_uFF01" class="headerlink" title="第五式：沧海一粟！！！！！"></a>第五式：沧海一粟！！！！！</h2><p>　　我们先把问题标准化，假定$f(x)$，$c_i(x)$，$h_j(x)$ 是定义在$R^n$上的连续可微函数，将下面约束最优化问题<br>$$<br>\min_{x}f(x)\\<br>s.t.\quad c_i(x)\le 0,\quad i=1,2,…,k\\<br>\quad \quad h_j(x)=0,\quad j=1,2,…,l<br>$$<br>称为原始问题。</p>
<p>　　然后引入广义拉格朗日函数<br>$$<br>L(x,\alpha,\beta)=f(x)+\sum_{i=1}^{k}\alpha_{i}c_i(x)+\sum_{j=1}^{l}\beta_{j}h_j(x)<br>$$<br>　　其中 $\alpha_i$ 和 $\beta_j$ 是拉格朗日乘子，$\alpha_i\ge 0$。然后经过一番推来导去眉来眼去，可以证明<br>$$<br>\min_x\max_{\alpha,\beta:\alpha_i\ge 0}L(x,\alpha,\beta)<br>$$<br>与原始问题具有相同的x最优解，称作广义拉格朗日函数的极小极大问题。</p>
<p>　　又有，当$f(x)$，$c_i(x)$，$h_j(x)$ 等满足一定条件时<br>$$<br>\max_{\alpha,\beta:\alpha_i\ge 0}\min_xL(x,\alpha,\beta)<br>$$<br>也与原始问题具有相同的x最优解，称作广义拉格朗日函数的极大极小问题，可以将此问题也改写成约束的形式：<br>$$<br>\max_{\alpha,\beta}\theta_D(\alpha,\beta)=\max_{\alpha,\beta}\min_xL(x,\alpha,\beta)\\<br>s.t.\qquad \alpha_i\ge 0,\quad i=1,2,…,k<br>$$<br>称作原始问题的对偶问题。</p>
<p>　　这一部分的具体细节懒得写了，估计你们也看不下去，真要有兴趣可以去看书，比如《凸优化》或者李航老师的《统计学习方法》，我上面的公式基本就是抄他的，但请注意书上附录C的KKT条件有误，(C.22)式和(C.23)式不应该包含在里面。</p>
<p>　　好啦，照此框架，来解决我们的问题：<br>$$<br>\max_{\alpha,\alpha_m\ge 0}\min_wL(w,\alpha)\\<br>=\max_{\alpha,\alpha_m\ge 0}\min_w\{-\frac{1}{N}\sum_{n=1}^N\sum_{k=1}^{K}1\{y_n=k\}\ln(\sum_{m=1}^{M-1}w_m\hat{y}_{nmk}+(1-\sum_{m=1}^{M-1}w_m)\hat{y}_{nMk})-\sum_{m=1}^{M-1}\alpha_mw_m-\alpha_M(1-\sum_{m=1}^{M-1}w_m)\}<br>$$<br>　　极大极小公式列出来很容易，如何求解才头疼。</p>
<p>　　最早接触拉格朗日对偶是看SVM的推导，最近研究在线分配的shale算法又遇到它，发现基本都是依靠KKT条件推导，然而后面各有各的玩法，没有什么普适的方案。我也试着从KKT出发，但始终没找到什么高效的方法，一赌气，干脆舍弃KKT直接求解极大极小问题。如果哪位高人有更高明的招式，请一定传授小弟。</p>
<p>　　我自己想的招式便是以不变应万变，依然按sgd的思路，每来一条样本，先固定 $\alpha$ 不动，更新w，这是关于w的极小化问题，使用梯度下降（依然梯度杀）；然后固定w，更新 $\alpha$，这是关于 $\alpha$ 的极大化问题，使用梯度上升（可称梯云纵）。对 $\alpha$ 的非负约束也很简单，更新后如果小于0，则置为0。</p>
<p>　　如此交错曲折，在解空间的山坡上忽上忽下苦苦寻觅，“路漫漫其修远兮”，正是</p>
<h2 id="u7B2C_u516D_u5F0F_uFF1A_u4E0A_u4E0B_u6C42_u7D22_uFF01_uFF01_uFF01_uFF01_uFF01_uFF01"><a href="#u7B2C_u516D_u5F0F_uFF1A_u4E0A_u4E0B_u6C42_u7D22_uFF01_uFF01_uFF01_uFF01_uFF01_uFF01" class="headerlink" title="第六式：上下求索！！！！！！"></a>第六式：上下求索！！！！！！</h2><p>　　具体的梯度计算如下：<br>$$<br>\frac{\partial l_n(w|\alpha)}{\partial w_m}=-\sum_{k=1}^{K}1\{y_n=k\}\frac{\hat{y}_{nmk}-\hat{y}_{nMk}}{\hat{y}_{nk}}-\alpha_m+\alpha_M,\quad m=1,…,M-1\\<br>\frac{\partial l_n(\alpha|w)}{\partial \alpha_m}=-w_m,\quad m=1,…,M-1\qquad\qquad\qquad\qquad\qquad\qquad\\<br>\frac{\partial l_n(\alpha|w)}{\partial \alpha_M}=-(1-\sum_{m=1}^{M-1}w_m)\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad<br>$$<br>　　adagrad代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys, math</span><br><span class="line"></span><br><span class="line">classNum = int(sys.argv[<span class="number">1</span>])</span><br><span class="line">modelNum = int(sys.argv[<span class="number">2</span>])</span><br><span class="line">alfa = float(sys.argv[<span class="number">3</span>])</span><br><span class="line">beta = <span class="number">1.0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> &gt;&gt; sys.stderr, <span class="string">"classNum="</span> + str(classNum)</span><br><span class="line"><span class="keyword">print</span> &gt;&gt; sys.stderr, <span class="string">"modelNum="</span> + str(modelNum)</span><br><span class="line"><span class="keyword">print</span> &gt;&gt; sys.stderr, <span class="string">"alfa="</span> + str(alfa)</span><br><span class="line"></span><br><span class="line">w = [<span class="number">1.0</span>] * modelNum</span><br><span class="line">n = [<span class="number">0.0</span>] * (modelNum-<span class="number">1</span>)</span><br><span class="line">A = [<span class="number">0.0</span>] * modelNum</span><br><span class="line">nA = [<span class="number">0.0</span>] * modelNum</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(w)):</span><br><span class="line">    w[i] /= modelNum</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> &gt;&gt; sys.stderr, w</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    seg = line.rstrip().split(<span class="string">" "</span>)</span><br><span class="line">    label = int(seg[<span class="number">0</span>])</span><br><span class="line">    x = []</span><br><span class="line">    <span class="keyword">for</span> tmp <span class="keyword">in</span> seg[<span class="number">1</span>:]:</span><br><span class="line">        seg2 = tmp.split(<span class="string">","</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(seg2)):</span><br><span class="line">            seg2[i] = float(seg2[i])</span><br><span class="line">        x.append(seg2)</span><br><span class="line">    pre = [<span class="number">0.0</span>] * classNum</span><br><span class="line">    <span class="keyword">for</span> m <span class="keyword">in</span> range(modelNum):</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> range(classNum):</span><br><span class="line">            pre[k] += w[m]*x[m][k]</span><br><span class="line">    g = [<span class="number">0.0</span>] * (modelNum-<span class="number">1</span>)</span><br><span class="line">    wsum = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> m <span class="keyword">in</span> range(modelNum-<span class="number">1</span>):</span><br><span class="line">        g[m] = (x[modelNum-<span class="number">1</span>][label]-x[m][label])/pre[label] - A[m] + A[modelNum-<span class="number">1</span>]</span><br><span class="line">        n[m] += g[m] * g[m]</span><br><span class="line">        lr = alfa/(beta+math.sqrt(n[m]))</span><br><span class="line">        w[m] -= lr * g[m]</span><br><span class="line">        wsum += w[m]</span><br><span class="line">        gA = -w[m]</span><br><span class="line">        nA[m] += gA * gA</span><br><span class="line">        lrA = alfa/(beta+math.sqrt(nA[m]))</span><br><span class="line">        A[m] += lrA * gA</span><br><span class="line">        <span class="keyword">if</span> A[m] &lt; <span class="number">0</span>:</span><br><span class="line">            A[m] = <span class="number">0</span></span><br><span class="line">    w[modelNum-<span class="number">1</span>] = <span class="number">1</span>-wsum</span><br><span class="line">    gA = -w[modelNum-<span class="number">1</span>]</span><br><span class="line">    nA[modelNum-<span class="number">1</span>] += gA * gA</span><br><span class="line">    lrA = alfa/(beta+math.sqrt(nA[modelNum-<span class="number">1</span>]))</span><br><span class="line">    A[modelNum-<span class="number">1</span>] += lrA * gA</span><br><span class="line">    <span class="keyword">if</span> A[modelNum-<span class="number">1</span>] &lt; <span class="number">0</span>:</span><br><span class="line">        A[modelNum-<span class="number">1</span>] = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> w:</span><br><span class="line">    <span class="keyword">print</span> x</span><br></pre></td></tr></table></figure>
<p>　　看一下效果，还是以上面的gender二分类为例，结果如下：</p>
<pre><code>0.123262252313    gender_cut_ftrl8000_val
0.0782768467103   gender_cut_ftrl_val
0.0340907260294   gender_nn_1005_val
0.243746308063    gender_cut_ftrl2000_val
0.447138729994    gender_cut_ftrl1000_val
0.0627800144873   gender_newFM_val
0.00261889445352  gender_xxFM_val
0.00808622794875  gender_result_fm
</code></pre><p>　　可以看到gender_xxFM_val和gender_result_fm的权重终于不再是负数，而且很小，接近于0，跟期望的一样，最后的logloss也基本一致，等于0.435125。</p>
<p>　　说明我们的方法很给力啊！不能骄傲，继续前行。上面的方法对最后一项权重$w_M$ 做了特殊处理，不够优雅，如果我们不专门处理它，而是把权重之和归一放在约束里呢？</p>
<h2 id="u7B2C_u4E03_u5F0F_uFF1A_u4E07_u6CD5_u5F52_u4E00_uFF01_uFF01_uFF01_uFF01_uFF01_uFF01_uFF01"><a href="#u7B2C_u4E03_u5F0F_uFF1A_u4E07_u6CD5_u5F52_u4E00_uFF01_uFF01_uFF01_uFF01_uFF01_uFF01_uFF01" class="headerlink" title="第七式：万法归一！！！！！！！"></a>第七式：万法归一！！！！！！！</h2><p>　　重新设计模型<br>$$<br>\hat{y}_{nk}=\sum_{m=1}^{M}w_m\hat{y}_{nmk}<br>$$<br>$$<br>\min_{w}f(w)=<br>\min_{w}\{-\frac{1}{N}\sum_{n=1}^N\sum_{k=1}^{K}1\{y_n=k\}\ln\hat{y}_{nk}\}\\<br>=\min_{w}\{-\frac{1}{N}\sum_{n=1}^N\sum_{k=1}^{K}1\{y_n=k\}\ln(\sum_{m=1}^{M}w_m\hat{y}_{nmk})\}\\<br>s.t.\qquad w_m\ge 0,\quad m=1,2,…,M\\<br>\sum_{m=1}^{M}w_m=1\qquad<br>$$<br>$$<br>L(w,\alpha,\beta)=-\frac{1}{N}\sum_{n=1}^N\sum_{k=1}^{K}1\{y_n=k\}\ln(\sum_{m=1}^{M}w_m\hat{y}_{nmk})-\sum_{m=1}^{M}\alpha_mw_m+\beta(\sum_{m=1}^{M}w_m-1)<br>$$<br>　　梯度计算<br>$$<br>\frac{\partial l_n(w|\alpha,\beta)}{\partial w_m}=-\sum_{k=1}^{K}1\{y_n=k\}\frac{\hat{y}_{nmk}}{\hat{y}_{nk}}-\alpha_m+\beta,\quad m=1,…,M\\<br>\frac{\partial l_n(\alpha|w,\beta)}{\partial \alpha_m}=-w_m,\quad m=1,…,M\qquad\qquad\qquad\qquad\qquad\\<br>\frac{\partial l_n(\beta|w,\alpha)}{\partial \beta}=\sum_{m=1}^{M}w_m-1\qquad\qquad\qquad\qquad\qquad\qquad\qquad<br>$$<br>　　代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys, math</span><br><span class="line"></span><br><span class="line">classNum = int(sys.argv[<span class="number">1</span>])</span><br><span class="line">modelNum = int(sys.argv[<span class="number">2</span>])</span><br><span class="line">alfa = float(sys.argv[<span class="number">3</span>])</span><br><span class="line">beta = <span class="number">1.0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> &gt;&gt; sys.stderr, <span class="string">"classNum="</span> + str(classNum)</span><br><span class="line"><span class="keyword">print</span> &gt;&gt; sys.stderr, <span class="string">"modelNum="</span> + str(modelNum)</span><br><span class="line"><span class="keyword">print</span> &gt;&gt; sys.stderr, <span class="string">"alfa="</span> + str(alfa)</span><br><span class="line"></span><br><span class="line">w = [<span class="number">1.0</span>] * modelNum</span><br><span class="line">nw = [<span class="number">0.0</span>] * modelNum</span><br><span class="line">A = [<span class="number">0.0</span>] * modelNum</span><br><span class="line">nA = [<span class="number">0.0</span>] * modelNum</span><br><span class="line">B = <span class="number">0.0</span></span><br><span class="line">nB = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(w)):</span><br><span class="line">    w[i] /= modelNum</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> &gt;&gt; sys.stderr, w</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    seg = line.rstrip().split(<span class="string">" "</span>)</span><br><span class="line">    label = int(seg[<span class="number">0</span>])</span><br><span class="line">    x = []</span><br><span class="line">    <span class="keyword">for</span> tmp <span class="keyword">in</span> seg[<span class="number">1</span>:]:</span><br><span class="line">        seg2 = tmp.split(<span class="string">","</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(seg2)):</span><br><span class="line">            seg2[i] = float(seg2[i])</span><br><span class="line">        x.append(seg2)</span><br><span class="line">    pre = [<span class="number">0.0</span>] * classNum</span><br><span class="line">    <span class="keyword">for</span> m <span class="keyword">in</span> range(modelNum):</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> range(classNum):</span><br><span class="line">            pre[k] += w[m]*x[m][k]</span><br><span class="line">    wsum = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> m <span class="keyword">in</span> range(modelNum):</span><br><span class="line">        gw = -x[m][label]/pre[label] - A[m] + B</span><br><span class="line">        nw[m] += gw * gw</span><br><span class="line">        lrw = alfa/(beta+math.sqrt(nw[m]))</span><br><span class="line">        w[m] -= lrw * gw</span><br><span class="line">        wsum += w[m]</span><br><span class="line">        gA = -w[m]</span><br><span class="line">        nA[m] += gA * gA</span><br><span class="line">        lrA = alfa/(beta+math.sqrt(nA[m]))</span><br><span class="line">        A[m] += lrA * gA</span><br><span class="line">        <span class="keyword">if</span> A[m] &lt; <span class="number">0</span>:</span><br><span class="line">            A[m] = <span class="number">0</span></span><br><span class="line">    gB = wsum - <span class="number">1</span></span><br><span class="line">    nB += gB * gB</span><br><span class="line">    lrB = alfa/(beta+math.sqrt(nB))</span><br><span class="line">    B += lrB * gB</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> w:</span><br><span class="line">    <span class="keyword">print</span> x</span><br></pre></td></tr></table></figure>
<p>　　效果</p>
<pre><code>0.117368795386    gender_cut_ftrl8000_val
0.0736857356383   gender_cut_ftrl_val
0.0387213072901   gender_nn_1005_val
0.236047170656    gender_cut_ftrl2000_val
0.463029142921    gender_cut_ftrl1000_val
0.069749655191    gender_newFM_val
0.00104464602712  gender_xxFM_val
0.00131312041348  gender_result_fm
</code></pre><p>　　注意，这里权重之和并不是严格的1，而是1.000959573523，毕竟是个迭代算法，没法保证严格的约束啊……所以计算logloss还是要重新归一下，最后logloss = 0.43512，跟前面的结果基本一致。</p>
<p>　　虽然最后两项的权重已经很接近于0，但看着还是很不爽，何不把很小的权重截成严格的0，就像生死符那样爽。对老司机来说都不是问题，上FTRL（为什么又是我）就好了嘛。</p>
<h2 id="u7B2C_u516B_u5F0F_uFF1A_u622A_u6743_u9053_uFF01_uFF01_uFF01_uFF01_uFF01_uFF01_uFF01_uFF01"><a href="#u7B2C_u516B_u5F0F_uFF1A_u622A_u6743_u9053_uFF01_uFF01_uFF01_uFF01_uFF01_uFF01_uFF01_uFF01" class="headerlink" title="第八式：截权道！！！！！！！！"></a>第八式：截权道！！！！！！！！</h2><p>　　FTRL的稀疏性就是专职干这的，将w的adagrad改成FTRL，代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys, math</span><br><span class="line"></span><br><span class="line">classNum = int(sys.argv[<span class="number">1</span>])</span><br><span class="line">modelNum = int(sys.argv[<span class="number">2</span>])</span><br><span class="line">alfa = float(sys.argv[<span class="number">3</span>])</span><br><span class="line">beta = <span class="number">1.0</span></span><br><span class="line"></span><br><span class="line">l1 = float(sys.argv[<span class="number">4</span>])</span><br><span class="line">l2 = float(sys.argv[<span class="number">5</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> &gt;&gt; sys.stderr, <span class="string">"classNum="</span> + str(classNum)</span><br><span class="line"><span class="keyword">print</span> &gt;&gt; sys.stderr, <span class="string">"modelNum="</span> + str(modelNum)</span><br><span class="line"><span class="keyword">print</span> &gt;&gt; sys.stderr, <span class="string">"alfa="</span> + str(alfa)</span><br><span class="line"><span class="keyword">print</span> &gt;&gt; sys.stderr, <span class="string">"l1="</span> + str(l1)</span><br><span class="line"><span class="keyword">print</span> &gt;&gt; sys.stderr, <span class="string">"l2="</span> + str(l2)</span><br><span class="line"></span><br><span class="line">w = [<span class="number">1.0</span>] * modelNum</span><br><span class="line">nw = [<span class="number">0.0</span>] * modelNum</span><br><span class="line">zw = [<span class="number">0.0</span>] * modelNum</span><br><span class="line">A = [<span class="number">0.0</span>] * modelNum</span><br><span class="line">nA = [<span class="number">0.0</span>] * modelNum</span><br><span class="line">B = <span class="number">0.0</span></span><br><span class="line">nB = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(w)):</span><br><span class="line">    w[i] /= modelNum</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> &gt;&gt; sys.stderr, w</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    seg = line.rstrip().split(<span class="string">" "</span>)</span><br><span class="line">    label = int(seg[<span class="number">0</span>])</span><br><span class="line">    x = []</span><br><span class="line">    <span class="keyword">for</span> tmp <span class="keyword">in</span> seg[<span class="number">1</span>:]:</span><br><span class="line">        seg2 = tmp.split(<span class="string">","</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(seg2)):</span><br><span class="line">            seg2[i] = float(seg2[i])</span><br><span class="line">        x.append(seg2)</span><br><span class="line">    pre = [<span class="number">0.0</span>] * classNum</span><br><span class="line">    avgp = [<span class="number">0.0</span>] * classNum</span><br><span class="line">    <span class="keyword">for</span> m <span class="keyword">in</span> range(modelNum):</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> range(classNum):</span><br><span class="line">            pre[k] += w[m]*x[m][k]</span><br><span class="line">            avgp[k] += x[m][k]/modelNum</span><br><span class="line">    wsum = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> m <span class="keyword">in</span> range(modelNum):</span><br><span class="line">        p = pre[label]</span><br><span class="line">        <span class="keyword">if</span> <span class="number">0</span> == p:</span><br><span class="line">            p = avgp[label]</span><br><span class="line">        gw = -x[m][label]/p - A[m] + B</span><br><span class="line">        sw = (math.sqrt(nw[m]+gw*gw)-math.sqrt(nw[m]))/alfa</span><br><span class="line">        zw[m] += gw - sw * w[m]</span><br><span class="line">        nw[m] += gw * gw</span><br><span class="line">        <span class="keyword">if</span> abs(zw[m]) &lt; l1:</span><br><span class="line">            w[m] = <span class="number">0</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            sgnz = <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> zw[m] &lt; <span class="number">0</span>:</span><br><span class="line">                sgnz = -<span class="number">1</span></span><br><span class="line">            w[m] = (sgnz*l1 - zw[m])/((beta + math.sqrt(nw[m]))/alfa + l2)</span><br><span class="line">        wsum += w[m]</span><br><span class="line">        gA = -w[m]</span><br><span class="line">        nA[m] += gA * gA</span><br><span class="line">        lrA = alfa/(beta+math.sqrt(nA[m]))</span><br><span class="line">        A[m] += lrA * gA</span><br><span class="line">        <span class="keyword">if</span> A[m] &lt; <span class="number">0</span>:</span><br><span class="line">            A[m] = <span class="number">0</span></span><br><span class="line">    gB = wsum - <span class="number">1</span></span><br><span class="line">    nB += gB * gB</span><br><span class="line">    lrB = alfa/(beta+math.sqrt(nB))</span><br><span class="line">    B += lrB * gB</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> w:</span><br><span class="line">    <span class="keyword">print</span> x</span><br></pre></td></tr></table></figure>
<p>　　注意这里L1正则要设的很大才行，比如100，效果如下：</p>
<pre><code>0.117563109491  gender_cut_ftrl8000_val
0.0734000016105 gender_cut_ftrl_val
0.0378296537773 gender_nn_1005_val
0.234723810866  gender_cut_ftrl2000_val
0.461201320728  gender_cut_ftrl1000_val
0.0747847726281 gender_newFM_val
0               gender_xxFM_val
0               gender_result_fm
</code></pre><p>　　哈哈，最后两项终于被彻底干掉，最后的logloss = 0.435117，依然保持的很好。</p>
<p>　　以上所有方法，在gender的7分类上也做了实验，同样有效，懒得再贴结果。<br><br><br>　　故事终于讲完了，Ensembling met Lagrange, and they lived happily ever after.<br><br><br><br><br>上一篇转到微信公众号时加了段作者简介：<br><small>本文作者：张卫，8年多码农生涯，先后在腾讯、搜狗混过些时日，目前在小米负责广告算法。无甚特别，唯好数学物理，正所谓推公式无敌手，推妹子无得手的中二汉子。</small></p>
<p>结果被人吐槽成了征婚帖，好吧，这次改一改：</p>
<p><small>本文作者：张卫，8年多码农生涯，先后在腾讯、搜狗混过些时日，目前在小米负责广告算法。曾经年少轻狂，颇好武侠旧学，晨舞葬诗魂的冷月刀，暮弄渡鹤影的寒塘剑；而今终日代码公式为伍，间或寄情文字，重举旧时觞。</small></p>

          
        
      </div>
      <footer>
        
          <div class="alignright">
            <a href="/2016/11/22/ensembling_lagrange/#more" class="more-link">Continue Reading<i class="fa fa-long-arrow-right fa-1"></i></a>
          </div>
        
        <div class="clearfix"></div>
      </footer>
    </div>
</article>



  

  <nav id="pagination">
  
  
  <div class="clearfix"></div>
</nav>




   </div></div>
    <aside id="sidebar" class="alignright"><div class="padding">
	
	  <div class="search">
  <form action="//google.com/search" method="get" accept-charset="utf-8">
    <input type="search" name="q" results="0" placeholder="搜索">
    <input type="hidden" name="q" value="site:yoursite.com">
  </form>
</div>
	
	  
<div class="widget recent-post">
  <h3 class="title">最新文章</h3>
  <ul class="entry">
    
      <li>
        <a href="/2017/10/21/ocpc_roi/">Paper Reading: OCPC, ROI</a>
      </li>
    
      <li>
        <a href="/2017/10/08/explore_exploit/">Paper Reading: Explore and Exploit</a>
      </li>
    
      <li>
        <a href="/2017/07/16/lambdafm/">lambdaFM</a>
      </li>
    
      <li>
        <a href="/2017/06/01/mlr_plm/">MLR, PLM</a>
      </li>
    
      <li>
        <a href="/2016/11/22/ensembling_lagrange/">Ensembling, Lagrange</a>
      </li>
    
      <li>
        <a href="/2016/10/16/fm_ftrl_softmax/">FM, FTRL, Softmax</a>
      </li>
    
      <li>
        <a href="/2016/02/05/cf_als/">CF的ALS算法推导</a>
      </li>
    
      <li>
        <a href="/2016/02/02/matrix_differential/">Matrix Differential</a>
      </li>
    
  </ul>
</div>


	
	  
	
	  
	
</div></aside>
    <div class="clearfix"></div>
  </div>
  <footer id="footer" class="inner"><div class="padding">
	<div class="alignleft">
	  
	  &copy; 2017 CastellanZhang
	  
	  Powerd by <a href="http://hexo.io/" target="_blank">hexo</a>
	  and Theme by <a href="https://github.com/halfer53/metro-light" target="_blank">metro-light</a>
	</div>

	<div class="alignright">
		
		
		
		
		
		
		
	</div>

	<div class="clearfix"></div>
</div>

<div class="scroll-top"><i class="fa fa-arrow-circle-up"></i></div></footer>
  


<script src="//cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/3.0.4/jquery.imagesloaded.js"></script>
<script src="/js/gallery.js"></script>



<script type="text/javascript">
$(window).scroll(function() {

    if($(this).scrollTop() > 400) {
        $('.scroll-top').fadeIn(200);
    } else {
        $('.scroll-top').fadeOut(200);
    }
});

$('.scroll-top').bind('click', function(e) {
    e.preventDefault();
    $('body,html').animate({scrollTop:0},200);
});
</script>


<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>
