<!DOCTYPE HTML>

    <html lang="zh-Hans">
  
<head>
  <meta charset="utf-8">
  
  <title>MLR, PLM | CastellanZhang&#39;s blog</title>
  <meta name="author" content="CastellanZhang">
  
  <meta name="description" content="MLR, PLM前言　　最近阿里的盖坤大神放出了一篇论文Learning Piece-wise Linear Models from Large Scale Data for Ad Click Prediction，介绍了阿里广告的一个主要ctr预估模型Large Scale Piece-wise ">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta property="og:title" content="MLR, PLM"/>
  <meta property="og:site_name" content="CastellanZhang&#39;s blog"/>

  
    <meta property="og:image" content="undefined"/>
  

  
    <meta http-equiv="Content-Language" content="zh-Hans"/>
  

  <link href="/img/favicon.png" rel="icon">
  
    <link rel="apple-touch-icon" href="/img/apple-icon.png">
    <link rel="apple-touch-icon-precomposed" href="/img/apple-icon.png">
    

  <link rel="alternate" href="/atom.xml" title="CastellanZhang&#39;s blog" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  
  <style type="text/css">
  /* Tim Pietrusky advanced checkbox hack (Android <= 4.1.2) */
body{ -webkit-animation: bugfix infinite 1s; }
@-webkit-keyframes bugfix { from {padding:0;} to {padding:0;} }

  
  <!-- Chinese readability improvements -->
    article {font-weight: 400;letter-spacing: .01rem;}
    article .entry{line-height:2;}
  

  
    article .post-content-index .entry{max-height: 550px; overflow:hidden;}
  
</style>

  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->

  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'null', 'auto');
  ga('send', 'pageview');
 
</script>




  
    <!-- 360 Font and Baidu CDN in China -->
    
      <link href='http://fonts.useso.com/css?family=Open+Sans:300,400|Playball' rel='stylesheet' type='text/css'>
    
  <link href='http://apps.bdimg.com/libs/fontawesome/4.1.0/css/font-awesome.css' rel='stylesheet' type='text/css'>
  <script src="http://libs.baidu.com/jquery/1.11.1/jquery.min.js"></script>
  



</head>


<body>
  <header id="header" class="inner"><div class="padding">
	<div class="alignleft logo">
	  <h1><a href="/">CastellanZhang&#39;s blog</a></h1>
	</div>
	<nav id="main-nav" class="alignright">
		<input type="checkbox" id="toggle" />
		<label for="toggle" class="toggle" data-open="Main Menu" data-close="Close Menu" onclick><i class="fa fa-bars"></i></label>
	  <ul class="menu">
	    
	      <li><a href="/">Home</a></li>
	    
	      <li><a href="/archives">Archives</a></li>
	    
	    
	  </ul>
	</nav>
	<div class="clearfix"></div>
</div>
</header>
  <div id="page-heading-wrap">
  	<div class="inner">
      <div class="padding">
    		
          <h1>MLR, PLM</h1>
          <ul>
            <li>
              <span class="heading-span">Posted on: </span>
              <time datetime="2017-06-01T15:25:17.000Z">Jun 1 2017</time>
            </li>
            
              <li>
                <span class="heading-span">By: </span>

                
                  <a href="/">CastellanZhang</a>
                

              </li>
            
            <li>
              <span class="heading-span">With: </span>
              
            </li>
          </ul>
        
      </div>
  	</div>
  </div>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper" class="padding"><article class="post">
  
  
    <div class="post-content">
  
      
      <div class="entry">
        
          <h1 id="MLR_2C_PLM"><a href="#MLR_2C_PLM" class="headerlink" title="MLR, PLM"></a>MLR, PLM</h1><h2 id="u524D_u8A00"><a href="#u524D_u8A00" class="headerlink" title="前言"></a>前言</h2><p>　　最近阿里的盖坤大神放出了一篇论文Learning Piece-wise Linear Models from Large Scale Data for Ad Click Prediction，介绍了阿里广告的一个主要ctr预估模型Large Scale Piece-wise Linear Model (LS-PLM)，在2012年就开始使用，据说早期叫做Mixture of LR(MLR)。</p>
<p>　　看完论文就很想验证一下效果，于是基于原来的<a href="https://github.com/CastellanZhang/alphaFM" target="_blank" rel="external">alphaFM</a>代码很快就实现了一个单机多线程版本，优化算法用了FTRL。完成代码的时候正好又赶上alphaGo完虐人类，于是命名仍然冠以alpha，叫做alphaPLM。</p>
<p>　　代码地址在：<br>　　<a href="https://github.com/CastellanZhang/alphaPLM" target="_blank" rel="external">https://github.com/CastellanZhang/alphaPLM</a></p>
<h2 id="u7B97_u6CD5_u539F_u7406"><a href="#u7B97_u6CD5_u539F_u7406" class="headerlink" title="算法原理"></a>算法原理</h2><p>　　PLM可以看做是混合了聚类和分类的思想，即将特征空间分片或者说分区间，每个分片就是一个聚类，每个聚类对应一个单独的线性模型LR。这里的聚类是软聚类，即每个样本可以属于多个分片，有概率分布。最后计算ctr是先算出在每个分片的ctr，再按属于各个分片的概率加权平均。通过分片线性拟合，达到了非线性的效果。</p>
<p>　　具体模型公式如下：</p>
<p>$$<br>p(y=1|x)=\sum_{i=1}^{m}\frac{e^{u_i^Tx}}{\sum_{j=1}^me^{u_j^Tx}}\cdot\frac{1}{1+e^{-w_i^Tx}}\\<br>=\sum_{i=1}^{m}\frac{e^{u_i^Tx}}{\sum_{j=1}^me^{u_j^Tx}}\cdot\sigma(w_i^Tx)<br>$$</p>
<p>　　可以看到，聚类部分是用了softmax函数，分类部分就是LR的sigmoid函数。该算法的巧妙之处就是将二者合成一个公式，一起训练参数。公式中m是分片数，属于超参数，由人工给定。模型参数是 $\Theta=\{u_1,…,u_m,w_1,…,w_m\}\in R^{d\times 2m}$，需要训练得到。</p>
<p>　　论文中的优化方法采用的是LBFGS，实现起来比较复杂，我为了快速验证算法效果，优化改成了FTRL，需要计算损失函数对u和w的梯度，下面给出推导。</p>
<p>　　首先对于 $y\in\{-1,1\}$，模型可以统一形式：</p>
<p>$$<br>p(y|x)=\sum_{i=1}^{m}\frac{e^{u_i^Tx}}{\sum_{j=1}^me^{u_j^Tx}}\cdot\frac{1}{1+e^{-yw_i^Tx}}\\<br>=\sum_{i=1}^{m}\frac{e^{u_i^Tx}}{\sum_{j=1}^me^{u_j^Tx}}\cdot\sigma(yw_i^Tx)<br>$$</p>
<p>　　单条样本(x,y)的损失函数：<br>$$<br>l(\Theta|x,y)=-\ln P(y|x,\Theta)=-\ln\frac{1}{\sum_{j=1}^me^{u_j^Tx}}\sum_{i=1}^{m}e^{u_i^Tx}\sigma(yw_i^Tx)\\<br>=\ln\sum_{j=1}^me^{u_j^Tx}-\ln(\sum_{i=1}^{m}e^{u_i^Tx}\sigma(yw_i^Tx))<br>$$<br>　　梯度计算：<br>$$<br>\nabla_{u_k}l=\frac{e^{u_k^Tx}x}{\sum_{j=1}^me^{u_j^Tx}}-\frac{e^{u_k^Tx}\sigma(yw_k^Tx)x}{\sum_{i=1}^{m}e^{u_i^Tx}\sigma(yw_i^Tx)}<br>$$<br>$$<br>\nabla_{w_k}l=\frac{ye^{u_k^Tx}\sigma(yw_k^Tx)(\sigma(yw_k^Tx)-1)x}{\sum_{i=1}^{m}e^{u_i^Tx}\sigma(yw_i^Tx)}<br>$$<br>　　后续的FTRL算法框架和alphaFM非常类似，不再详述，可以参见之前的<a href="http://castellanzhang.github.io/2016/10/16/fm_ftrl_softmax/" target="_blank" rel="external">文档</a>和实现代码。</p>
<h2 id="u7B97_u6CD5_u6548_u679C"><a href="#u7B97_u6CD5_u6548_u679C" class="headerlink" title="算法效果"></a>算法效果</h2><p>　　论文中给了一个demo数据的例子，如下图：</p>
<p><img src="/img/plm.jpg" alt=""></p>
<p>　　我们可以通过代码生成类似的样本，来验证一下算法效果：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#demo_data1.py</span></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> random <span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line">n = int(sys.argv[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">    x = <span class="number">2</span> * random() - <span class="number">1.0</span></span><br><span class="line">    y = <span class="number">2</span> * random() - <span class="number">1.0</span></span><br><span class="line">    label = <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> abs(x) + abs(y) &lt; <span class="number">1.0</span>:</span><br><span class="line">        label = <span class="number">0</span></span><br><span class="line">    <span class="keyword">print</span> str(label) + <span class="string">" x:"</span> + str(x) + <span class="string">" y:"</span> + str(y)</span><br></pre></td></tr></table></figure></p>
<p>　　生成1万条训练样本和2000条测试样本：</p>
<p>　　<code>python demo_data1.py 10000 &gt; train.txt</code></p>
<p>　　<code>python demo_data1.py 2000 &gt; test.txt</code></p>
<p>　　alphaPLM的训练参数如下：</p>
<p>　　<code>cat train.txt | ./plm_train -m model.txt -u_bias 1 -w_bias 1 -u_l1 0.001 -u_l2 0.1 -w_l1 0.001 -w_l2 0.1 -core 1 -piece_num 4 -u_stdev 1 -w_stdev 1 -u_alpha 10 -w_alpha 10</code></p>
<p>　　在测试集的AUC可以达到0.99以上。</p>
<p>　　如果是LR或FM，你会发现无论你怎么调参，AUC始终在0.5左右。</p>
<p>　　直观上也很容易理解，看图就会发现，如果特征就是x和y的坐标值的话，数据非线性可分，而很明显在四个象限的分片里分别都是线性可分的。</p>
<p>　　你心里是否已经忍不住开始唾弃LR：“啊呸，LR果然是个战五渣！连这么个demo数据都搞不定！”那你可就冤枉LR了，原始特征非线性，完全可以通过转换变成线性或近似线性，比如做个简单的离散化就会大不一样：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#demo_data2.py</span></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> random <span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line">n = int(sys.argv[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">    x = <span class="number">2</span> * random() - <span class="number">1.0</span></span><br><span class="line">    y = <span class="number">2</span> * random() - <span class="number">1.0</span></span><br><span class="line">    label = <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> abs(x) + abs(y) &lt; <span class="number">1.0</span>:</span><br><span class="line">        label = <span class="number">0</span></span><br><span class="line">    fx = <span class="string">"x"</span> + str(int(x*<span class="number">10</span>)) + <span class="string">":1"</span></span><br><span class="line">    fy = <span class="string">"y"</span> + str(int(y*<span class="number">10</span>)) + <span class="string">":1"</span></span><br><span class="line">    <span class="keyword">print</span> str(label) + <span class="string">" "</span> + fx + <span class="string">" "</span> + fy</span><br></pre></td></tr></table></figure></p>
<p>　　重新生成1万条训练样本和2000条测试样本：</p>
<p>　　<code>python demo_data2.py 10000 &gt; train.txt</code></p>
<p>　　<code>python demo_data2.py 2000 &gt; test.txt</code></p>
<p>　　此时你会发现，无论LR、FM还是PLM，AUC都很容易达到0.99以上。</p>
<p>　　而在我们广告业务的真实数据中，LR所面对的几乎都是千万维或上亿维的高维离散特征，效果并不会比FM或PLM差太多。我在真实数据的实验也验证了这一点，PLM和FM相比LR提升的都差不多，AUC基本都是在千分位提高几个点。</p>

        
      </div>
      <footer>
        
          
          
          <div class="share">
  
</div>
          
<nav class="article-nav clearfix">
 
 <div class="article-prev" >
 <a href="/2017/07/16/lambdafm/" title="lambdaFM">
  <i class="fa fa-long-arrow-left"></i>
  <span>
  lambdaFM</span>
</a>
</div>


<div class="article-next">
<a href="/2016/11/22/ensembling_lagrange/"  title="Ensembling, Lagrange">
 <span>Ensembling, Lagrange
</span>
<i class="fa fa-long-arrow-right"></i>
</a>
</div>

</nav>

        
        <div class="clearfix"></div>
      </footer>
    </div>
</article>


<section id="comment">
  <h2 class="title">留言</h2>

  
</section>

</div></div>
    <aside id="sidebar" class="alignright"><div class="padding">
	
	  <div class="search">
  <form action="//google.com/search" method="get" accept-charset="utf-8">
    <input type="search" name="q" results="0" placeholder="搜索">
    <input type="hidden" name="q" value="site:yoursite.com">
  </form>
</div>
	
	  
<div class="widget recent-post">
  <h3 class="title">最新文章</h3>
  <ul class="entry">
    
      <li>
        <a href="/2017/10/21/ocpc_roi/">Paper Reading: OCPC, ROI</a>
      </li>
    
      <li>
        <a href="/2017/10/08/explore_exploit/">Paper Reading: Explore and Exploit</a>
      </li>
    
      <li>
        <a href="/2017/07/16/lambdafm/">lambdaFM</a>
      </li>
    
      <li>
        <a href="/2017/06/01/mlr_plm/">MLR, PLM</a>
      </li>
    
      <li>
        <a href="/2016/11/22/ensembling_lagrange/">Ensembling, Lagrange</a>
      </li>
    
      <li>
        <a href="/2016/10/16/fm_ftrl_softmax/">FM, FTRL, Softmax</a>
      </li>
    
      <li>
        <a href="/2016/02/05/cf_als/">CF的ALS算法推导</a>
      </li>
    
      <li>
        <a href="/2016/02/02/matrix_differential/">Matrix Differential</a>
      </li>
    
  </ul>
</div>


	
	  
	
	  
	
</div></aside>
    <div class="clearfix"></div>
  </div>
  <footer id="footer" class="inner"><div class="padding">
	<div class="alignleft">
	  
	  &copy; 2017 CastellanZhang
	  
	  Powerd by <a href="http://hexo.io/" target="_blank">hexo</a>
	  and Theme by <a href="https://github.com/halfer53/metro-light" target="_blank">metro-light</a>
	</div>

	<div class="alignright">
		
		
		
		
		
		
		
	</div>

	<div class="clearfix"></div>
</div>

<div class="scroll-top"><i class="fa fa-arrow-circle-up"></i></div></footer>
  


<script src="//cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/3.0.4/jquery.imagesloaded.js"></script>
<script src="/js/gallery.js"></script>



<script type="text/javascript">
$(window).scroll(function() {

    if($(this).scrollTop() > 400) {
        $('.scroll-top').fadeIn(200);
    } else {
        $('.scroll-top').fadeOut(200);
    }
});

$('.scroll-top').bind('click', function(e) {
    e.preventDefault();
    $('body,html').animate({scrollTop:0},200);
});
</script>


<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>
