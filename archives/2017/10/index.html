<!DOCTYPE HTML>

    <html lang="zh-Hans">
  
<head>
  <meta charset="utf-8">
  
  <title>归档：2017/10 | CastellanZhang&#39;s blog</title>
  <meta name="author" content="CastellanZhang">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
  <meta property="og:site_name" content="CastellanZhang&#39;s blog"/>

  
    <meta property="og:image" content="undefined"/>
  

  
    <meta http-equiv="Content-Language" content="zh-Hans"/>
  

  <link href="/img/favicon.png" rel="icon">
  
    <link rel="apple-touch-icon" href="/img/apple-icon.png">
    <link rel="apple-touch-icon-precomposed" href="/img/apple-icon.png">
    

  <link rel="alternate" href="/atom.xml" title="CastellanZhang&#39;s blog" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  
  <style type="text/css">
  /* Tim Pietrusky advanced checkbox hack (Android <= 4.1.2) */
body{ -webkit-animation: bugfix infinite 1s; }
@-webkit-keyframes bugfix { from {padding:0;} to {padding:0;} }

  
  <!-- Chinese readability improvements -->
    article {font-weight: 400;letter-spacing: .01rem;}
    article .entry{line-height:2;}
  

  
    article .post-content-index .entry{max-height: 550px; overflow:hidden;}
  
</style>

  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->

  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'null', 'auto');
  ga('send', 'pageview');
 
</script>




  
    <!-- 360 Font and Baidu CDN in China -->
    
      <link href='http://fonts.useso.com/css?family=Open+Sans:300,400|Playball' rel='stylesheet' type='text/css'>
    
  <link href='http://apps.bdimg.com/libs/fontawesome/4.1.0/css/font-awesome.css' rel='stylesheet' type='text/css'>
  <script src="http://libs.baidu.com/jquery/1.11.1/jquery.min.js"></script>
  



</head>


<body>
  <header id="header" class="inner"><div class="padding">
	<div class="alignleft logo">
	  <h1><a href="/">CastellanZhang&#39;s blog</a></h1>
	</div>
	<nav id="main-nav" class="alignright">
		<input type="checkbox" id="toggle" />
		<label for="toggle" class="toggle" data-open="Main Menu" data-close="Close Menu" onclick><i class="fa fa-bars"></i></label>
	  <ul class="menu">
	    
	      <li><a href="/">Home</a></li>
	    
	      <li><a href="/archives">Archives</a></li>
	    
	    
	  </ul>
	</nav>
	<div class="clearfix"></div>
</div>
</header>
  <div id="page-heading-wrap">
  	<div class="inner">
      <div class="padding">
    		
          <h2></h2>
        
      </div>
  	</div>
  </div>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper" class="padding">
<h2 class="archive-title">2017/10</h2>


  
    <article class="post">
  
  
    <div class="post-content-index">
  
      
        <header>
          <div class="icon"></div>
            
    
      <h1 class="title transition"><a href="/2017/10/21/ocpc_roi/">Paper Reading: OCPC, ROI</a></h1>
    
  
          <ul>
            <li>
              <span class="heading-span">Posted on: </span>
              <time datetime="2017-10-20T17:06:51.000Z">Oct 21 2017</time>
            </li>
            
              <li>
                <span class="heading-span">By: </span>

                
                  <a href="/">CastellanZhang</a>
                

              </li>
            
            <li>
              <span class="heading-span">With: </span>
              
          </ul>
        </header>
      
      <div class="entry">
        
          
            <h1 id="u8BBA_u6587_u5B66_u4E60_uFF1AOCPC_2C_ROI"><a href="#u8BBA_u6587_u5B66_u4E60_uFF1AOCPC_2C_ROI" class="headerlink" title="论文学习：OCPC, ROI"></a>论文学习：OCPC, ROI</h1><h2 id="u524D_u8A00"><a href="#u524D_u8A00" class="headerlink" title="前言"></a>前言</h2><p>　　翻 KDD2017的论文，又瞅见了阿里的这篇Optimized Cost per Click in Taobao Display Advertising，好文章常看常新，重看一遍写个学习笔记，同时把论文里省略的证明补充一下。</p>
<p>　　这篇论文详细介绍了阿里展示广告的OCPC（Optimized Cost per Click）机制，以手机淘宝首页的Banner广告（Banner CPC Ads，广告可以是商品、店铺或品牌）和猜你喜欢版块的广告（Item CPC Ads，猜你喜欢200个推荐位里包含3个广告位都是具体商品）为例。</p>
<p>　　广告系统是一个三方博弈的生态，要同时兼顾用户体验、广告主利益、平台收入三方的诉求。淘宝广告的计费方式为CPC，即广告主事先设定单次点击出价bid price，每次请求来了广告系统预测用户点击概率pCTR，然后按照bid*pCTR即eCPM排序，分数高的广告获得展示，如果用户点击了广告则广告平台获得广告主的费用bid price（为了简化问题暂先忽略GSP的影响）。</p>
<p>　　按照这种方式主要是以广告平台的收入为优化目标，广告主即便出高价获得了流量但是ROI没法保证，即流量质量没法保证。广告主可以对不同的广告位不同的人群设定不同的出价来缓解，但粒度还是太粗了，如果广告系统能在每次请求这个细粒度上根据pCVR来帮助广告主自动调整出价就完美了，即pCVR高的请求出价高，pCVR低的请求出价低，保证ROI不会降，这就是OCPC的核心思想。</p>
<p>　　淘宝的广告主还有一个特点，他们本身就是淘宝的商家，且大部分是中小商家，GMV是他们的最重要诉求，广告预算一般都是占他们GMV的固定比例，因此提高GMV还能带来广告预算的增长，对广告平台的长期发展也是有利的。GMV提高一定程度上也反映了用户体验的提高，毕竟你推的广告被用户相中了还消费了。</p>
<p>　　至此，算法的框架已经基本成型：以ROI不降为约束，通过算法自动调整出价来尽量优化eCPM和GMV。</p>
<h2 id="u7B97_u6CD5_u7EC6_u8282"><a href="#u7B97_u6CD5_u7EC6_u8282" class="headerlink" title="算法细节"></a>算法细节</h2><h3 id="1-__u5148_u7ED9_u51FA_u4E00_u7CFB_u5217_u5B9A_u4E49"><a href="#1-__u5148_u7ED9_u51FA_u4E00_u7CFB_u5217_u5B9A_u4E49" class="headerlink" title="1. 先给出一系列定义"></a>1. 先给出一系列定义</h3><ul>
<li>定义用户$u$在点击广告$a$之后发生交易转化事件$c$的概率为$p(c|u,a)$，也就是所谓的从点击到购买的转化率CVR。</li>
<li>定义$v_a$为广告商品$a$的pay-per-buy(PPB)，也就是商家的收入，因此单次点击的期望GMV为$p(c|u,a)*v_a$。</li>
<li>用户$u$对广告$a$的单次点击的期望ROI，这里忽略GSP的影响：<br>$$<br>roi_{(u,a)}=\frac{p(c|u,a)*v_a}{b_a}<br>$$</li>
<li>广告$a$在一段时间内总的期望ROI为：<br>$$<br>roi_a=\frac{v_a\cdot\sum_u n_u\cdot p(c|u,a)}{b_a\cdot\sum_u n_u}=\frac{E_u[p(c|u,a)]\cdot v_a}{b_a}<br>$$<br>其中$n_u$为一段时间内用户$u$对广告$a$的点击次数。$E_u[p(c|u,a)]$ 的计算可以通过一段时间内预测模型给出的广告$a$所有pCVR值求均值得到，但要去除最大10%和最小10%的pCVR值，目的应该是去除异常点，使结果更加准确可靠。</li>
</ul>
<h3 id="2-_bid_u4F18_u5316_u7684_u4E0A_u4E0B_u754C"><a href="#2-_bid_u4F18_u5316_u7684_u4E0A_u4E0B_u754C" class="headerlink" title="2. bid优化的上下界"></a>2. bid优化的上下界</h3><p>　　$roi_a$与$E_u[p(c|u,a)]$ 成线性关系，对于单次请求，假设出价从$b_a$调整为$b_a^*$，只要满足<br>$$<br>\frac{b_a^*}{b_a}\le\frac{p(c|u,a)}{E_u[p(c|u,a)]}<br>$$<br>即能保证$roi_a$不降。</p>
<p>　　论文给出的最终上下界如下，其实在其中考虑商业利益做了一定的妥协，并不能保证所有广告的ROI都一定不降，论文后面的实验结果也说明了这一点，大部分广告的ROI都有提高，少部分有降，但总体还是提高了，<br>$$<br>l(b_a^*)=<br>\begin{cases}<br>b_a\cdot(1-r_a), &amp; \frac{p(c|u,a)}{E_u[p(c|u,a)]}&lt;1 \\<br>b_a, &amp; \frac{p(c|u,a)}{E_u[p(c|u,a)]}\ge 1 \\<br>\end{cases} \\<br>u(b_a^*)=<br>\begin{cases}<br>b_a, &amp; \frac{p(c|u,a)}{E_u[p(c|u,a)]}&lt;1 \\<br>b_a\cdot\min(1+r_a,\frac{p(c|u,a)}{E_u[p(c|u,a)]}), &amp; \frac{p(c|u,a)}{E_u[p(c|u,a)]}\ge 1 \\<br>\end{cases}<br>$$<br>其中$l(b_a^*)$ 为下限，$u(b_a^*)$ 为上限，还有个上下浮动的阈值参数$r_a$（比如40%），看下图更加明显，灰色区域为$b_a^*$ 的候选取值范围，即所谓的可行域（feasible region）。可以看到当流量质量较差时，$b_a^*$ 的上限还能到$b_a$ 本身，这显然是不能保证ROI不降的，这里做了妥协。</p>
<p><img src="/img/ocpc_figure3.jpg" alt=""></p>
<h3 id="3-_Ranking"><a href="#3-_Ranking" class="headerlink" title="3. Ranking"></a>3. Ranking</h3><p>　　在依赖eCPM的排序机制下，在可行域内选取不同的$b_a^*$ 可能会导致排序结果的不同，进而影响到其他的指标。</p>
<p>　　先看最简单的情况，只有1个广告位，候选广告集合A中共有n个广告，通过调整出价来竞争这个广告位，优化问题的数学形式如下：<br>$$<br>\max_{b_1^*,\cdots,b_n^*}f(k,b_k^*)\qquad\qquad\qquad\qquad \\<br>s.t.\qquad k=\mathop{\arg\max}_i\ pctr_i*b_i^* \\<br>\qquad\qquad l(b_i^*)\le b_i^*\le u(b_i^*),\forall i\in A<br>$$<br>　　$k$是最终胜出的广告，依赖于$b_1^*,\cdots,b_n^*$ 的选取，$f(\cdot)$ 是需要优化的目标函数，综合了我们关注的指标。比如下面两个例子：<br>$$<br>f_1(k,b_k^*)=pctr_k*pcvr_k*v_k\qquad\qquad\qquad \\<br>f_2(k,b_k^*)=pctr_k*pcvr_k*v_k+\alpha*pctr_k*b_k^*<br>$$<br>　　$f_1$只考虑GMV，而$f_2$同时考虑GMV和eCPM即广告平台收入。论文后面的实验部分给出了一种更复杂的形式，同样是综合GMV和eCPM：<br>$$<br>f(k,b_k^*)=pctr_k*b_k^**(1+\sigma(\frac{pcvr_k*v_k*||A||}{\sum_{i\in A}pcvr_i*v_i},w)*r_a)<br>$$<br>其中$w=6$，$r_a=0.4$，$\sigma(x,w)=\frac{x^w-1}{x^w+1}$，当$w&gt;0$时，$\sigma(x,w)$ 是一个关于$x$的值域范围(-1,1)的单调增函数。</p>
<p>　　以上所有的$f(k,b_k^*)$ 函数都是$b_k^*$ 的单调增函数（更准确的说应该是单调非减函数，论文里没有严格区分），这为后面的ranking算法提供了便利。一般来说，这个单调增的假设也是合理的，毕竟出价高了对于大部分指标都是好事。<br><br></p>
<ul>
<li>优化问题求解方法：<br>设$s_a^*=pctr_a*b_a^*$，则$s_a^*$ 的下界和上界分别为$l(s_a^*)=pctr_a*l(b_a^*)$，$u(s_a^*)=pctr_a*u(b_a^*)$，将所有的$f(i,u(b_i^*))$ 按降序排列，然后按顺序找出第一个广告$k$，满足$u(s_k^*)$ 大于等于其他所有的$l(s_i^*)$，这个$k$就是最终展示的广告，且$b_k^*=u(b_k^*)$。<br><br></li>
<li>论文省略了求解方法正确性的严格证明，这里补充一下：<br>a. 首先最终结果$b_k^*$ 一定等于$u(b_k^*)$。<br>反证法：假设最终结果为$b_k^*$，且 $b_k^*\lt u(b_k^*)$ 。由约束可知 $pctr_k*b_k^*$ 大于等于其他所有的$pctr_i*b_i^*$，若取新的$b_k^{+}=u(b_k^*)$，则有$pctr_k*b_k^{+}&gt;pctr_k*b_k^*$，$pctr_k*b_k^{+}$ 仍然大于等于其他所有的$pctr_i*b_i^*$，即最终胜出的广告还是$k$，但由$f(\cdot)$ 的单调递增性，$f(k,b_k^{+})&gt;f(k,b_k^*)$，矛盾。<br>b. 由a可知，$f(\cdot)$ 的最大值一定是某个$f(i,u(b_i^*))$，$i$从1到$n$。我们当然希望越大越好，因此从大到小排列挨个检验，$f(k,u(b_k^*))$ 能雀屏中选的前提是$u(b_k^*)$ 实力够硬，能够在其他$b_i^*$ 配合的情况下满足约束条件：$pctr_k*u(b_k^*)$ 大于等于其他所有的$pctr_i*b_i^*$，既然其他$b_i^*$ 很配合，当然都取最小值$l(b_i^*)$ 最好，所以$u(b_k^*)$ 的条件放松到$pctr_k*u(b_k^*)$ 大于等于其他所有的$pctr_i*l(b_i^*)$，也即$u(s_k^*)$ 大于等于其他所有的$l(s_i^*)$。<br>证毕。<br>综上，$f(\cdot)$ 的单调性是算法正确性的保证，复杂度也不高，主要就是个排序。<br><p><br>　　说完1个广告位的情况，再推广到N个广告位，算法如下图，本质上是个贪心算法，先按照1个广告位的算法找出广告$k$放到广告位1，然后调整剩下广告的$u(s_i^*)\le u(s_k^*)$，不然$k$就不能保证排在第1位了，同时调整剩下广告的$u(b_i^*)$，接着在剩下的广告中按1个广告位的算法找出第2个广告位的广告，依次类推：</p></li>
</ul>
<p><img src="/img/ocpc_alg1.jpg" alt=""></p>
<h3 id="4-__u6A21_u578B_u6821_u6B63_uFF08Calibration_uFF09"><a href="#4-__u6A21_u578B_u6821_u6B63_uFF08Calibration_uFF09" class="headerlink" title="4. 模型校正（Calibration）"></a>4. 模型校正（Calibration）</h3><p>　　论文提到他们模型的pCVR有偏差，当真实CVR越大，pCVR和真实CVR的比值越大，也即偏差越大，所以需要校正。论文根据实验观察给出了一个校正的经验公式：<br>$$<br>p(c|u,a)=<br>\begin{cases}<br>p(c|u,a), &amp; p(c|u,a)&lt;tc \\<br>p(c|u,a)*(1+\log(\frac{p(c|u,a)}{tc})), &amp; p(c|u,a)\ge tc \\<br>\end{cases}<br>$$<br>$tc$为阈值，取0.012。我们之前的做法是采用保序回归，不知道孰优孰劣。</p>
<h3 id="5-__u6A21_u578B_u8BC4_u4F30"><a href="#5-__u6A21_u578B_u8BC4_u4F30" class="headerlink" title="5. 模型评估"></a>5. 模型评估</h3><p>　　CTR/CVR模型线下评估一般都用AUC，论文提到Google的那篇Wide &amp; Deep Learning for Recommender Systems里表明线下AUC高上线可能效果反而变差。Wide &amp; Deep那篇论文我之前看过，是说他们的纯Deep模型相比纯Wide模型（即LR）线下AUC降了，但线上效果反而提升了，Google作者也没给出很好的解释。</p>
<p>　　这篇阿里的论文也说他们碰到了类似的现象，于是想出一个新的指标Group AUC (GAUC)，即将测试数据按照用户u和广告位p的组合(u,p)分组计算AUC（如果某个组全是正样本或全是负样本，则忽略这个组），最后再按权重求平均，权重可以是各组的展示次数或点击次数。具体公式如下：<br>$$<br>GAUC=\frac{\sum_{(u,p)}w_{(u,p)}*AUC_{(u,p)}}{\sum_{(u,p)}w_{(u,p)}}<br>$$<br>　　可惜论文并没详细说这么做到底能带来多少好处，是否真的解决了前面AUC线下和线上不一致的弊端。</p>
<h2 id="u5B9E_u9A8C_u7ED3_u679C"><a href="#u5B9E_u9A8C_u7ED3_u679C" class="headerlink" title="实验结果"></a>实验结果</h2><p>　　论文分线下模拟和线上效果做了很多角度的实验对比，这里只记录几个主要的部分。</p>
<h3 id="1-__u7EBF_u4E0B_u6A21_u62DF"><a href="#1-__u7EBF_u4E0B_u6A21_u62DF" class="headerlink" title="1. 线下模拟"></a>1. 线下模拟</h3><p>　　通过历史的log数据，将pCTR和pCVR当做真实的CTR和CVR，比如某次展示的广告计算出pCTR为4%，则认为贡献了0.04的点击。然后设计各种策略，统计关心的指标。</p>
<p>一共有4种策略：</p>
<ul>
<li>Strategy 0为对照组，保持原来线上的状态</li>
<li>Strategy 1站在广告主角度，设定一个简单的调价格规则$b_a^*=b_a*(1+\sigma(\frac{p(c|u,a)}{E_u[p(c|u,a)]},w)*r_a)$</li>
<li>Strategy 2就是OCPC策略，优化的目标函数前面说过，是$f(k,b_k^*)=pctr_k*b_k^**(1+\sigma(\frac{pcvr_k*v_k*||A||}{\sum_{i\in A}pcvr_i*v_i},w)*r_a)$</li>
<li>Strategy 3不调出价而是直接修改rankscore公式，不再是eCPM排序，而改成按$pctr*pcvr*bid$，很明显是想提升GMV</li>
</ul>
<p>　　实验结果如下图，相对Strategy 0，Strategy 1和3的GPM（即千次展示GMV）和ROI都提高了但RPM降了，只有Strategy 2即OCPC策略在3个指标上都获得了提升，达到三方共赢。</p>
<p><img src="/img/ocpc_table1.jpg" alt=""></p>
<h3 id="2-__u7EBF_u4E0A_u6548_u679C"><a href="#2-__u7EBF_u4E0A_u6548_u679C" class="headerlink" title="2. 线上效果"></a>2. 线上效果</h3><p>　　Strategy 2相比Strategy 0和线下模拟一致，依然在三个指标上都获得了提升，见下图：</p>
<p><img src="/img/ocpc_table4.jpg" alt=""></p>
<p>　　论文始终强调，这套机制具有普适性，并不局限于GMV，论文给出一个例子，双十一前淘宝商家更加关注商品加入购物篮的量，于是使用模型预测的商品加入购物篮概率pASR，修改目标函数为：<br>$f(k,b_k^*)=pctr_k*b_k^**(1+\sigma(\frac{pasr_k*||A||}{\sum_{i\in A}pasr_i},w)*r_a)$，<br>相比旧的公式，ASR指标提升15.6%。</p>
<h2 id="u603B_u7ED3"><a href="#u603B_u7ED3" class="headerlink" title="总结"></a>总结</h2><p>　　这又是一篇从实践中来的论文，针对真实场景的问题建模，算法原理也不是多么的高深复杂，却取得了很好的效果。阿里在广告主数据方面得天独厚，广告主本身就是淘宝商家，ROI的数据可以轻易获得。如果是别的广告平台想做ROI优化可能会困难重重，首先各家广告主的ROI诉求可能千差万别，其次数据共享更是难如登天。</p>

          
        
      </div>
      <footer>
        
          <div class="alignright">
            <a href="/2017/10/21/ocpc_roi/#more" class="more-link">Continue Reading<i class="fa fa-long-arrow-right fa-1"></i></a>
          </div>
        
        <div class="clearfix"></div>
      </footer>
    </div>
</article>



  
    <article class="post">
  
  
    <div class="post-content-index">
  
      
        <header>
          <div class="icon"></div>
            
    
      <h1 class="title transition"><a href="/2017/10/08/explore_exploit/">Paper Reading: Explore and Exploit</a></h1>
    
  
          <ul>
            <li>
              <span class="heading-span">Posted on: </span>
              <time datetime="2017-10-08T10:18:23.000Z">Oct 8 2017</time>
            </li>
            
              <li>
                <span class="heading-span">By: </span>

                
                  <a href="/">CastellanZhang</a>
                

              </li>
            
            <li>
              <span class="heading-span">With: </span>
              
          </ul>
        </header>
      
      <div class="entry">
        
          
            <h1 id="u8BBA_u6587_u5B66_u4E60_uFF1AExplore_and_Exploit"><a href="#u8BBA_u6587_u5B66_u4E60_uFF1AExplore_and_Exploit" class="headerlink" title="论文学习：Explore and Exploit"></a>论文学习：Explore and Exploit</h1><h2 id="u524D_u8A00"><a href="#u524D_u8A00" class="headerlink" title="前言"></a>前言</h2><p>　　前阵子读了一篇KDD2017的论文”A Practical Exploration System for Search Advertising”，是有关E&amp;E算法的，放假无事便调研了一些相关资料，做个小结。</p>
<p>　　计算广告和推荐系统中经常会碰到某些长尾广告或长尾item从来没有机会或者很少机会的展示，导致CTR预估非常不准，需要探索性地创造机会给它们一定的展示量，但又不能带来太大的损失。这种问题一般称作Explore and Exploit问题。</p>
<p>　　在学术界经常把它描述成为一个多臂赌博机问题(multi-armed bandit problem, MAB)，若干台赌博机，每次可以选择一台机器摇一下，有一定概率会吐钱出来，但各台机器吐钱概率不一致且未知，那么赌徒每次该如何选择来最大化收益？对于K-armed bandit problem数学定义为：</p>
<p>　　$i$ 为机器下标，$1\le i\le K$ ，每台机器对应一组随机变量$X_{i,1},X_{i,2},X_{i,3}…$，表示每次被选中后的收益，这组随机变量独立同分布，期望 $\mu_i$未知。</p>
<p>　　策略A是一个算法，每次选择一台机器获得其收益，定义$T_i(n)$ 为前n次选择中机器$i$被选中的次数，定义策略A的前n次选择的regret为：<br>$$<br>\mu^*n-\mu_j\sum_{j=1}^{K}E[T_j(n)]<br>$$<br>　　其中<br>$$<br>\mu^*\mathop{=}^{def}\max_{1\le i\le K}\mu_i<br>$$<br>　　regret越小表示策略A越好，看起来有点像online learning的regret定义。下面总结几种最近调研的E&amp;E算法。</p>
<h2 id="u4E00_uFF1A_u7EAF_u968F_u673A"><a href="#u4E00_uFF1A_u7EAF_u968F_u673A" class="headerlink" title="一：纯随机"></a>一：纯随机</h2><p>　　最简单的办法，每次随机选。</p>
<h2 id="u4E8C_uFF1A_u6700_u5927_u5747_u503C"><a href="#u4E8C_uFF1A_u6700_u5927_u5747_u503C" class="headerlink" title="二：最大均值"></a>二：最大均值</h2><p>　　先随机选若干次，然后一直选均值最大的。</p>
<h2 id="u4E09_uFF1A_24_5Cepsilon_24-Greedy"><a href="#u4E09_uFF1A_24_5Cepsilon_24-Greedy" class="headerlink" title="三：$\epsilon$-Greedy"></a>三：$\epsilon$-Greedy</h2><p>　　设定参数 $\epsilon\in(0,1]$，每次以 $\epsilon$ 的概率随机选一个机器，否则选择当前收益均值最大的机器。</p>
<p>　　论文[1]中给出了一个变种算法：$\epsilon_n$-Greedy，具体为 $\epsilon$ 不再固定，而是以1/n的速率衰减，可以证明比原始方法有更好的regret。具体见论文[1]的Theorem 3。</p>
<h2 id="u56DB_uFF1AThompson_Sampling"><a href="#u56DB_uFF1AThompson_Sampling" class="headerlink" title="四：Thompson Sampling"></a>四：Thompson Sampling</h2><p>　　对于收益为1和0二值的情况，可以假定每台机器$i$收益符合参数为$p_i$的伯努利分布，假定参数 $p_i\sim Beta(\alpha_i,\beta_i)$，（搞过LDA的应该都知道Beta分布和伯努利分布的共轭关系）。</p>
<p>　　算法具体为：每一轮每台机器用其当前自身的Beta分布生成一个数$p$，本轮选择$p$最大的那台机器，假定下标为$i$；然后观察其收益，如果为1则 $\alpha_i$加1，为0则 $\beta_i$加1。</p>
<h2 id="u4E94_uFF1AUCB_28Upper_Confidence_Bound_29"><a href="#u4E94_uFF1AUCB_28Upper_Confidence_Bound_29" class="headerlink" title="五：UCB(Upper Confidence Bound)"></a>五：UCB(Upper Confidence Bound)</h2><p>　　论文[1]中不止一个UCB，这里只介绍最简单的UCB1。</p>
<p>　　1. 初始化：每台机器选择一次</p>
<p>　　2. 循环：选择机器$i$，满足<br>$$<br>i=\mathop{\arg\max}_{1\le j\le K}(\bar x_j+\sqrt{\frac{2\ln n}{n_j}})<br>$$<br>　　其中，$\bar x_j$是机器$j$的平均收益，$n_j$是机器$j$被选中的次数，$n$为总的轮次数。</p>
<p>　　算法思想很明白，历史均值加上一个置信区间来估计本轮的收益，历史被选中的次数越少则置信区间越大，会加大被选中的机会。</p>
<p>　　可以证明，UCB的regret量级为O(log n)，具体证明过程见论文[1]，证明过程比较复杂，我看了很久才看明白，会用到Chernoff-Hoeffding bound不等式和1/n^2的无穷级数求和。</p>
<h2 id="u516D_uFF1ALinUCB"><a href="#u516D_uFF1ALinUCB" class="headerlink" title="六：LinUCB"></a>六：LinUCB</h2><p>　　LinUCB算法是雅虎2010年提出的，用于新闻推荐，见论文[2]。考虑到前面几种算法都过于简单，根本没有考虑到个性化的问题，不同的user对于同样的item的期望收益（比如CTR）也是不一样的，且item本身也可能随时间动态变化，因此论文[2]重新定义了考虑上下文的MAB问题，在第t轮：</p>
<p>　　1. 算法A观察到当前用户$u_t$和当前的item候选集$A_t$，对于每一个$a\in A_t$和当前$u_t$，有一个特征向量$x_{t,a}$，即代表上下文</p>
<p>　　2. 通过前t-1轮的收益结果，算法A选择一个$a_t\in A_t$，然后得到收益$r_{t,a_t}$，这里 $r_{t,a_t}$ 的期望与$u_t$和$a_t$都有关</p>
<p>　　3. 根据新的观测值 $(x_{t,a_t},a_t,r_{t,a_t})$，算法A更新选择策略</p>
<p></p><p><br>　　论文[2]中给出两种LinUCB，我们这里只说相对简单的第一种。</p>
<p>　　LinUCB假定$r_{t,a}$ 的期望值和 $x_{t,a}$ 成线性关系，这也是LinUCB名字的来历，具体为：<br>$$<br>E[r_{t,a}|x_{t,a}]=x_{t,a}^T\theta_a^*<br>$$<br>　　可以看到每一个item $a$对应一个未知参数 $\theta_a^*$，可以通过历史数据来估计。假定在第t轮的时候，$a$被选中过m次，对应的特征向量和收益构成训练数据 $(D_a,c_a)$，$D_a$为$m\times d$矩阵，即m个特征向量，$c_a$为$m\times 1$向量，即m个收益。</p>
<p>　　通过岭回归可以得到 $\theta_a^*$ 的估计值：<br>$$<br>\hat\theta_a=(D_a^TD_a+I_d)^{-1}D_a^Tc_a<br>$$<br><br></p>
<hr style="height:1px;border:none;border-top:1px dashed #0066CC;">

<h3 id="u5907_u6CE8-_u5CAD_u56DE_u5F52_u7684_u63A8_u5BFC_uFF1A"><a href="#u5907_u6CE8-_u5CAD_u56DE_u5F52_u7684_u63A8_u5BFC_uFF1A" class="headerlink" title="备注-岭回归的推导："></a>备注-岭回归的推导：</h3><p>　　对于线性回归$D\theta=c$，采用最小二乘和L2正则项来估计参数 $\theta$.<br>$$<br>\min_\theta f(\theta)=\min_\theta||c-D\theta||_2^2+\lambda||\theta||_2^2\\<br>f(\theta)=(c-D\theta)^T(c-D\theta)+\lambda\theta^T\theta\\<br>\Rightarrow df=(d(c-D\theta))^T(c-D\theta)+(c-D\theta)^Td(c-D\theta)+\lambda(d\theta)^T\theta+\lambda\theta^Td\theta\\<br>=2(c-D\theta)^Td(c-D\theta)+2\lambda\theta^Td\theta\\<br>=-2(c-D\theta)^TDd\theta+2\lambda\theta^Td\theta<br>$$<br>　　令$df=0$，有<br>$$<br>D^T(c-D\theta)=\lambda\theta\\<br>\Rightarrow D^Tc=(D^TD+\lambda I)\theta\\<br>\Rightarrow \theta=(D^TD+\lambda I)^{-1}D^Tc<br>$$</p>
<p><hr style="height:1px;border:none;border-top:1px dashed #0066CC;"><br><br><br>　　回到正题，得到 $\hat\theta_a$后，有：</p>
<p>　　对于任意 $\delta&gt;0,\alpha=1+\sqrt{\ln(2/\delta)/2}$，<br>$$<br>P\left\{\left|x_{t,a}^T\hat\theta_a-E[r_{t,a}|x_{t,a}]\right|\le\alpha\sqrt{x_{t,a}^T(D_a^TD_a+I_d)^{-1}x_{t,a}}\right\}\ge1-\delta<br>$$<br>　　这部分的推导要用到论文[3]的定理，我还没来得及细看。</p>
<p>　　有了这个置信区间的不等式，就可以类似UCB算法一样，在第t轮选择：<br>$$<br>a_t\mathop{=}^{def}\mathop{\arg\max}_{a\in A_t}\left(x_{t,a}^T\hat\theta_a+\alpha\sqrt{x_{t,a}^T(D_a^TD_a+I_d)^{-1}x_{t,a}}\right)<br>$$<br>　　算法具体如下图：</p>
<p><img src="/img/LinUCB.jpg" alt=""></p>
<p>　　可以看到，算法涉及矩阵求逆等运算，如果特征向量维度很高，计算会很复杂。因此论文[2]介绍了如何构建特征，主要是如何降维。user相关的原始特征1193维，item相关的原始特征83维，user特征用 $\phi_u$ 表示，item特征用 $\phi_a$ 表示。用LR构建点击模型来拟合历史数据，不过线性部分比较特别，形式为 $\phi_u^TW\phi_a$，即考虑了user和item的所有二阶特征组合，通过LR训练出参数矩阵$W$后，将user特征投影到item的特征空间：<br>$$<br>\psi_u\mathop{=}^{def}\phi_u^TW<br>$$<br>　　然后再聚类为5个簇，再加上偏置项，即特征向量 $x_{t,a}$ 一共只有6维，计算将大大简化。</p>
<p>　　论文[2]还有一个有意思的部分，介绍了如何offline来评估E&amp;E算法的好坏。比如我们有一份完全随机策略的log数据，希望能够线下评估我们新的E&amp;E算法A，具体为：</p>
<p>　　1. 依次扫描log数据的每一条记录，如果展示的item和算法A给出的不一致，则丢弃该条记录，直到找到和算法A一致的一条记录</p>
<p>　　2. 该记录加入到算法A的历史，算法A更新选择策略</p>
<p>　　3. 该记录的收益加入到A的总收益，如果A的历史记录不够T条，回到第1步，从上次的位置继续扫描</p>
<p>　　4. 直到A的历史数据达到T条，最后输出总收益除以T</p>
<h2 id="u4E03_uFF1AExploration_Algorithm_for_Search_Ads"><a href="#u4E03_uFF1AExploration_Algorithm_for_Search_Ads" class="headerlink" title="七：Exploration Algorithm for Search Ads"></a>七：Exploration Algorithm for Search Ads</h2><p>　　前面的算法都是把E&amp;E独立出来讲，假如我们的业务已经有了一个click model，那该如何和E&amp;E结合呢？A Practical Exploration System for Search Advertising[4]给出了一个很好的方案。这篇论文来自KDD2017，是雅虎搜索广告团队的工作。</p>
<p>　　冷启动问题特化到计算广告领域，就是指广告主向广告系统提交新的广告，系统很难准确预估新广告的CTR，带来的后果是新的广告可能拿不到多少展示量，click model不能很快学习到这些“冷广告”的点击概率，影响整体效果（比如收入）。</p>
<p>　　仔细分析，如果对新广告的CTR预估高了还好一些，初期就会有足够的展示量，只要模型更新及时，很快学习到更加准确的点击率，然后恢复正常；如果新广告的CTR预估很低，拿不到展示量，模型不能学到准确点击率，即使模型更新，预估还是偏低，恶性循环，导致本来质量不错的新广告永远拿不到量。</p>
<p>　　因此这篇论文的思想便是对CTR预估较低的新广告做boosting，加大预估CTR，具体实现结合了 $\epsilon$-Greedy和UCB的思路。<br><br></p>
<hr style="height:1px;border:none;border-top:1px dashed #0066CC;">

<h3 id="u4E00_u4E9B_u80CC_u666F_u77E5_u8BC6_uFF1A"><a href="#u4E00_u4E9B_u80CC_u666F_u77E5_u8BC6_uFF1A" class="headerlink" title="一些背景知识："></a>一些背景知识：</h3><p>　　搜索广告被Matching模块召回，但拿不到展示量的原因主要有：</p>
<p>　　1. Ad-Quality Filtering(AQF)：广告质量不行被过滤掉，而一般来说预估CTR是质量分的一个重要组成部分，所以预估CTR低了，很可能在这里就被干掉。</p>
<p>　　2. Reserve Price：出于商业利益，广告系统一般会设定一个最低价格的限制，如果bid*pCTR低于这个最低价格，则连参与竞价的机会都没有。</p>
<p>　　3. Auction：最后竞价环节，狼多肉少，广告坑位有限，大家按rank-score排序，分高者胜出。而bid*pCTR又是rank-score的最重要组成部分。</p>
<p>　　显然，这人生的三道坎都与预估CTR直接相关，可见click model何等重要。</p>
<p>　　click model干的事就是给定搜索词q、广告a、用户u之后，预估u对a的点击概率p(click|q,a,u)，一般都采用基于特征的监督学习模型。而最重要的特征往往是所谓的点击反馈特征，即历史点击数和历史展示数以及二者的比值历史CTR，如果考虑了位置偏置，就变成EC/COEC特征。</p>
<p>　　EC/COEC在多个雅虎的论文里提到过，不过最早的出处应该是2007年的这篇[5]。简单来说，搜索广告位有多个，比如竖排一列，不同rank的点击率天然就有差异，一般高处rank的偏高，低处rank的偏低，这就是位置偏置。这种天然点击率可以通过统计每一个rank上的所有点击除以所有展示来得到，当然这是一种近似值，因为广告系统会把rank-sore高的广告往高rank处放，这样统计又引入了rank-score偏置，除非开一部分流量完全随机出广告。</p>
<p>　　我们将每个rank上的天然点击率记为 $ctr(r)$，r为rank编号。比如 $ctr(r_1)$ 是 $ctr(r_2)$ 的两倍，广告A在$r_1$上展示了1000次，点击了100次，广告B在$r_2$上展示了1000次，点击了80次，如果直接将这些数字作为特征的话，模型可能会学出广告A的点击率大于广告B，但其实考虑位置偏置，广告A的点击率小于B才是合理的。</p>
<p>　　为此定义expected clicks(EC)为某个广告a在rank r上的期望点击数：<br>$$<br>ec(r,a)=ctr(r)*i_r(a)<br>$$<br>其中 $i_r(a)$ 为a在rank r上的实际展示数。</p>
<p>　　定义clicks over expected clicks(COEC)如下：<br>$$<br>COEC(a)=\frac{\sum_r c(r,a)}{\sum_r ec(r,a)}<br>$$<br>　　其中 $c(r,a)$ 为a在rank r上的实际点击数。</p>
<p>　　$EC(a)=\sum_r ec(r,a)$ 可以看做是广告a历史展示数的一种normalization，如果非要在绝对值上较真的话可以除以最大的 $ctr(r)$，变成<br>$$<br>EC(a)/\max_r ctr(r)，<br>$$<br>即认为最好位置的展示数1次才算1次，其他位置都要打折。</p>
<p>　　同理，COEC(a)可以看做是对广告a的历史CTR做normalize，去除位置偏置。</p>
<p><hr style="height:1px;border:none;border-top:1px dashed #0066CC;"><br><br><br>　　论文算法具体如下图，该算法应放在click model输出预估CTR之后、auction模块之前：</p>
<p><img src="/img/Exploration_Algorithm_for_Search_Ads.jpg" alt=""></p>
<p>　　1：输入，包括当前搜索词q，用户u，召回的广告列表，相应的pCTR，出价bids，和每个广告的历史展示数（去除了位置偏置）。还贴心地准备了一个黑名单列表，即在黑名单里的新广告就不要指望boosting了，听天由命吧，应该是防止严重影响用户体验的广告得到boosting。</p>
<p>　　2：参数，下面碰到了细说。</p>
<p>　　3：照搬 $\epsilon$-Greedy的思路，只在小流量上做Exploration，论文给出的参数 $\epsilon=0.05$，还是比较保守的。</p>
<p>　　4：设定一个要参与Exploration的广告候选集E，先置为空集。</p>
<p>　　5：构建候选集E，对所有召回的广告，如果pCTR小于阈值 $p_{th}$ 且历史展示数小于阈值 $n_{th}$ 且不在黑名单的，加入E。即只对足够新的、预估CTR偏低的广告做Exploration。论文给出的参数 $n_{th}=500$，$p_{th}$ 和AQF模块的阈值一致，为0.02。</p>
<p>　　6：E集合还是偏大，做不到人人有份，所以要抽签决定最终参与boosting的广告，最多 $r_{max}$ 个，论文给出的 $r_{max}$ 只有2。这里抽签的方法要细讲一下，因为论文是把这个作为一个创新点的。抽签采用轮盘赌的方式而不是纯随机，bid越大，被选中的概率越大。这样做的好处有三，一是选出bid高的，最终在auction环节胜出的几率也大，否则折腾半天都白费功夫了；二是保证整体的price-per-click(PPC)够高，防范Exploration带来收入上的损失；三是给了广告主一个正反馈，广告主经常抱怨我在你们这投了新广告钱出的老高怎么量不见涨啊，这下好了，给钱好办事，你出价高我给你量就多，一定程度上还能刺激收入。</p>
<p>　　7：最重要的boosting，将pCTR变大，仿照的是UCB的思路，即在原来pCTR的基础上加上个置信区间。这里的置信区间给的有些任性，论文似乎想从伯努利分布的标准差推导出来，但很不严谨。不管了，反正还有两个参数要调，$\beta$ 是防止分母为0，$\alpha$ 要好好调调，保证boosting之后的广告能有80%越过AQF那道坎。</p>
<p>　　8：形成最终集合F，经过boosting的广告和剩下的广告合并。这里公式似乎有误，$k\in T\setminus[m]$ 应该是 $k\in [m]\setminus T$。</p>
<p>　　9：把最终集合F送到auction模块。</p>
<p></p><p><br>　　算法评估：</p>
<p>　　1. Learning Rate Metrics：论文定义了一个函数，评估新广告从冷变热的速度，实验证明相比对照组，引入boosting后确实变快了。意料之中，无需细说。</p>
<p>　　2. Business Metrics：这是实打实的指标，相比对照组，RPM提升了1%，CTR和PPC等都有一点提升。</p>
<p>　　3. Good versus Bad Ads：这个E&amp;E算法前面说了，就是要帮助本来质量不错的新广告不要被淹没，实验发现有9.5%的Good Ads被挽救了回来。</p>
<p></p><p><br>　　整篇论文给人的感觉就是很“工程”，没有繁琐的理论推导，而有详细的算法框架，原理也很简单直接，还给出了具体参数，最后再给出实际线上效果让你放心。总之就是对我等工程师很友好，拿来即可用，稍微改改就能用到搜索、推荐等领域。</p>
<p><br></p>
<hr>
<p>参考文献：<br>[1] Finite-time Analysis of the Multiarmed Bandit Problem, 2002<br>[2] A Contextual-Bandit Approach to Personalized News Article Recommendation, 2010<br>[3] Exploring compact reinforcement-learning representations with linear regression, 2009<br>[4] A Practical Exploration System for Search Advertising, 2017<br>[5] Comparing Click Logs and Editorial Labels for Training Query Rewriting, 2007</p>

          
        
      </div>
      <footer>
        
          <div class="alignright">
            <a href="/2017/10/08/explore_exploit/#more" class="more-link">Continue Reading<i class="fa fa-long-arrow-right fa-1"></i></a>
          </div>
        
        <div class="clearfix"></div>
      </footer>
    </div>
</article>



  

  <nav id="pagination">
  
  
  <div class="clearfix"></div>
</nav>




   </div></div>
    <aside id="sidebar" class="alignright"><div class="padding">
	
	  <div class="search">
  <form action="//google.com/search" method="get" accept-charset="utf-8">
    <input type="search" name="q" results="0" placeholder="搜索">
    <input type="hidden" name="q" value="site:yoursite.com">
  </form>
</div>
	
	  
<div class="widget recent-post">
  <h3 class="title">最新文章</h3>
  <ul class="entry">
    
      <li>
        <a href="/2017/10/21/ocpc_roi/">Paper Reading: OCPC, ROI</a>
      </li>
    
      <li>
        <a href="/2017/10/08/explore_exploit/">Paper Reading: Explore and Exploit</a>
      </li>
    
      <li>
        <a href="/2017/07/16/lambdafm/">lambdaFM</a>
      </li>
    
      <li>
        <a href="/2017/06/01/mlr_plm/">MLR, PLM</a>
      </li>
    
      <li>
        <a href="/2016/11/22/ensembling_lagrange/">Ensembling, Lagrange</a>
      </li>
    
      <li>
        <a href="/2016/10/16/fm_ftrl_softmax/">FM, FTRL, Softmax</a>
      </li>
    
      <li>
        <a href="/2016/02/05/cf_als/">CF的ALS算法推导</a>
      </li>
    
      <li>
        <a href="/2016/02/02/matrix_differential/">Matrix Differential</a>
      </li>
    
  </ul>
</div>


	
	  
	
	  
	
</div></aside>
    <div class="clearfix"></div>
  </div>
  <footer id="footer" class="inner"><div class="padding">
	<div class="alignleft">
	  
	  &copy; 2017 CastellanZhang
	  
	  Powerd by <a href="http://hexo.io/" target="_blank">hexo</a>
	  and Theme by <a href="https://github.com/halfer53/metro-light" target="_blank">metro-light</a>
	</div>

	<div class="alignright">
		
		
		
		
		
		
		
	</div>

	<div class="clearfix"></div>
</div>

<div class="scroll-top"><i class="fa fa-arrow-circle-up"></i></div></footer>
  


<script src="//cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/3.0.4/jquery.imagesloaded.js"></script>
<script src="/js/gallery.js"></script>



<script type="text/javascript">
$(window).scroll(function() {

    if($(this).scrollTop() > 400) {
        $('.scroll-top').fadeIn(200);
    } else {
        $('.scroll-top').fadeOut(200);
    }
});

$('.scroll-top').bind('click', function(e) {
    e.preventDefault();
    $('body,html').animate({scrollTop:0},200);
});
</script>


<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>
